{"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9915012,"sourceType":"datasetVersion","datasetId":6092801}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"markdown","source":["# Artificial Neural Networks and Deep Learning---## Homework 1: Minimal Working ExampleTo make your first submission, follow these steps:1. Create a folder named `[2024-2025] AN2DL/Homework 1` in your Google Drive.2. Upload the `training_set.npz` file to this folder.3. Upload the Jupyter notebook `Homework 1 - Minimal Working Example.ipynb`.4. Load and process the data.5. Implement and train your model.6. Submit the generated `.zip` file to Codabench."],"metadata":{"id":"nuwVgG3Vbbka"}},{"cell_type":"markdown","source":["## 🌐 Connect Colab to Google Drive"],"metadata":{"id":"dw_-hFm6bjY6"}},{"cell_type":"code","source":["!pip install tensorflow==2.17.0 keras==3.4.1 tensorflow-decision-forests==1.10.0 tensorflow-text==2.17.0 tf-keras==2.17.0 google keras_cv"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nSFqEXpz7qbQ","outputId":"72f12ef0-3106-4407-9253-2f7c4a46299f","execution":{"iopub.status.busy":"2024-11-17T08:12:44.211059Z","iopub.execute_input":"2024-11-17T08:12:44.211986Z","iopub.status.idle":"2024-11-17T08:14:11.913568Z","shell.execute_reply.started":"2024-11-17T08:12:44.211935Z","shell.execute_reply":"2024-11-17T08:14:11.912389Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tensorflow==2.17.0\n","  Downloading tensorflow-2.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n","Collecting keras==3.4.1\n","  Downloading keras-3.4.1-py3-none-any.whl.metadata (5.8 kB)\n","Collecting tensorflow-decision-forests==1.10.0\n","  Downloading tensorflow_decision_forests-1.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.0 kB)\n","Collecting tensorflow-text==2.17.0\n","  Downloading tensorflow_text-2.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n","Requirement already satisfied: tf-keras==2.17.0 in /usr/local/lib/python3.10/dist-packages (2.17.0)\n","Requirement already satisfied: google in /usr/local/lib/python3.10/dist-packages (2.0.3)\n","Collecting keras_cv\n","  Downloading keras_cv-0.9.0-py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (0.2.0)\n","Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (3.12.1)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (18.1.1)\n","Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (0.4.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (24.2)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (4.25.5)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (2.32.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (75.1.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (2.5.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (4.12.2)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (1.16.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (1.67.1)\n","Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (2.17.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (0.37.1)\n","Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (1.26.4)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras==3.4.1) (13.9.4)\n","Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras==3.4.1) (0.0.8)\n","Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras==3.4.1) (0.13.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from tensorflow-decision-forests==1.10.0) (2.2.2)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from tensorflow-decision-forests==1.10.0) (0.45.0)\n","Collecting wurlitzer (from tensorflow-decision-forests==1.10.0)\n","  Downloading wurlitzer-3.1.1-py3-none-any.whl.metadata (2.5 kB)\n","Collecting ydf (from tensorflow-decision-forests==1.10.0)\n","  Downloading ydf-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from google) (4.12.3)\n","Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from keras_cv) (2024.9.11)\n","Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.10/dist-packages (from keras_cv) (4.9.7)\n","Collecting keras-core (from keras_cv)\n","  Downloading keras_core-0.1.7-py3-none-any.whl.metadata (4.3 kB)\n","Requirement already satisfied: kagglehub in /usr/local/lib/python3.10/dist-packages (from keras_cv) (0.3.4)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.17.0) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.17.0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.17.0) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.17.0) (2024.8.30)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow==2.17.0) (3.7)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow==2.17.0) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow==2.17.0) (3.1.3)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->google) (2.6)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kagglehub->keras_cv) (4.66.6)\n","Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from keras-core->keras_cv) (0.1.8)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->tensorflow-decision-forests==1.10.0) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->tensorflow-decision-forests==1.10.0) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->tensorflow-decision-forests==1.10.0) (2024.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras==3.4.1) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras==3.4.1) (2.18.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (8.1.7)\n","Requirement already satisfied: immutabledict in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (4.2.0)\n","Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (2.3)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (5.9.5)\n","Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (17.0.0)\n","Requirement already satisfied: simple-parsing in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (0.1.6)\n","Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (1.13.1)\n","Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (0.10.2)\n","Requirement already satisfied: array-record>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (0.5.1)\n","Requirement already satisfied: etils>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets->keras_cv) (1.10.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets->keras_cv) (2024.10.0)\n","Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets->keras_cv) (6.4.5)\n","Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets->keras_cv) (3.21.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras==3.4.1) (0.1.2)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow==2.17.0) (3.0.2)\n","Requirement already satisfied: docstring-parser<1.0,>=0.15 in /usr/local/lib/python3.10/dist-packages (from simple-parsing->tensorflow-datasets->keras_cv) (0.16)\n","Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-metadata->tensorflow-datasets->keras_cv) (1.66.0)\n","Downloading tensorflow-2.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (601.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m601.3/601.3 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading keras-3.4.1-py3-none-any.whl (1.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tensorflow_decision_forests-1.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.5/15.5 MB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tensorflow_text-2.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading keras_cv-0.9.0-py3-none-any.whl (650 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m650.7/650.7 kB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading keras_core-0.1.7-py3-none-any.whl (950 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m950.8/950.8 kB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading wurlitzer-3.1.1-py3-none-any.whl (8.6 kB)\n","Downloading ydf-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.3/9.3 MB\u001b[0m \u001b[31m77.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: ydf, wurlitzer, keras-core, keras, tensorflow, tensorflow-text, tensorflow-decision-forests, keras_cv\n","  Attempting uninstall: keras\n","    Found existing installation: keras 3.5.0\n","    Uninstalling keras-3.5.0:\n","      Successfully uninstalled keras-3.5.0\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.17.1\n","    Uninstalling tensorflow-2.17.1:\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/gdrive')\n","%cd /gdrive/My Drive/[2024-2025] AN2DL/Homework 1"],"metadata":{"id":"y2S4GWr3Uoa8","execution":{"iopub.status.busy":"2024-11-15T11:03:22.493823Z","iopub.execute_input":"2024-11-15T11:03:22.494206Z","iopub.status.idle":"2024-11-15T11:03:22.826118Z","shell.execute_reply.started":"2024-11-15T11:03:22.494168Z","shell.execute_reply":"2024-11-15T11:03:22.825043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## ⚙️ Import Libraries"],"metadata":{"id":"d7IqZP5Iblna"}},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras as tfk\n","from tensorflow.keras import layers as tfkl\n","\n","import numpy as np\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","\n","import matplotlib.pyplot as plt\n","import keras_cv\n","\n","import numpy as np\n","import tensorflow as tf\n","import keras_cv\n","from tensorflow import keras as tfk\n","from tensorflow.keras import layers, models, applications\n","from tensorflow.keras.callbacks import LambdaCallback\n","import random\n","import keras\n","from keras.saving import register_keras_serializable\n","\n","np.random.seed(42)\n","tf.random.set_seed(42);"],"metadata":{"id":"CO6_Ft_8T56A","execution":{"iopub.status.busy":"2024-11-17T08:14:43.509705Z","iopub.execute_input":"2024-11-17T08:14:43.510090Z","iopub.status.idle":"2024-11-17T08:14:43.516035Z","shell.execute_reply.started":"2024-11-17T08:14:43.510053Z","shell.execute_reply":"2024-11-17T08:14:43.514985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## ⏳ Load the Data"],"metadata":{"id":"GN_cpHlSboXV"}},{"cell_type":"code","source":["# Carica il dataset\n","data = np.load('training_set.npz')\n","X_train = data['images']\n","y_train = data['labels']\n","\n","\"\"\"# Carica il dataset\n","data2 = np.load('/kaggle/input/blood-cells/test_set.npz')\n","X_test2 = data['images']\n","y_test2 = data['labels']\"\"\"\n","\n","# Converti y in one-hot encoding\n","y_train = tf.keras.utils.to_categorical(y_train, num_classes=8)\n","#y_test2 = tf.keras.utils.to_categorical(y_test2, num_classes=8)"],"metadata":{"id":"pLaoDaG1V1Yg","execution":{"iopub.status.busy":"2024-11-17T08:14:49.626447Z","iopub.execute_input":"2024-11-17T08:14:49.627116Z","iopub.status.idle":"2024-11-17T08:14:56.162709Z","shell.execute_reply.started":"2024-11-17T08:14:49.627074Z","shell.execute_reply":"2024-11-17T08:14:56.161739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import hashlib\n","\n","def image_hash(image):\n","    image_bytes = image.tobytes()\n","    return hashlib.sha256(image_bytes).hexdigest()\n","\n","unique_images = []\n","unique_labels = []\n","duplicate_positions = set()\n","\n","seen_hashes = {}\n","\n","for i in range(len(X_train)):\n","    img_hash = image_hash(X_train[i])\n","    if img_hash not in seen_hashes:\n","        if i not in duplicate_positions:\n","            unique_images.append(X_train[i])\n","            unique_labels.append(y_train[i])\n","        seen_hashes[img_hash] = i\n","    else:\n","        duplicate_positions.add(seen_hashes[img_hash])\n","        duplicate_positions.add(i)\n","\n","X_train = [X_train[i] for i in range(len(X_train)) if i not in duplicate_positions]\n","y_train = [y_train[i] for i in range(len(y_train)) if i not in duplicate_positions]\n","\n","X_train = np.array(X_train)\n","y_train = np.array(y_train)\n"],"metadata":{"id":"rJesjkncAkkR","execution":{"iopub.status.busy":"2024-11-17T08:15:03.790978Z","iopub.execute_input":"2024-11-17T08:15:03.791994Z","iopub.status.idle":"2024-11-17T08:15:05.052590Z","shell.execute_reply.started":"2024-11-17T08:15:03.791943Z","shell.execute_reply":"2024-11-17T08:15:05.051665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# split train in training and test set\n","X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n"],"metadata":{"id":"5FxPNaJEa8RC","execution":{"iopub.status.busy":"2024-11-17T08:15:15.551402Z","iopub.execute_input":"2024-11-17T08:15:15.551828Z","iopub.status.idle":"2024-11-17T08:15:15.659219Z","shell.execute_reply.started":"2024-11-17T08:15:15.551790Z","shell.execute_reply":"2024-11-17T08:15:15.658009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_test[0]"],"metadata":{"id":"cxexV_-ENWd_","execution":{"iopub.status.busy":"2024-11-15T11:09:36.923565Z","iopub.execute_input":"2024-11-15T11:09:36.923939Z","iopub.status.idle":"2024-11-15T11:09:36.933040Z","shell.execute_reply.started":"2024-11-15T11:09:36.923904Z","shell.execute_reply":"2024-11-15T11:09:36.931916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 🛠️ Train and Save the Model"],"metadata":{"id":"FSliIxBvbs2Q"}},{"cell_type":"code","source":["class MyModel:\n","    def __init__(self):\n","        \"\"\"\n","        Inizializza lo stato interno del modello MobileNetV3Small pre-addestrato.\n","        \"\"\"\n","        self.neural_network = self.create_model()\n","\n","    def get_augmentation_layer(self):\n","        # Definizione dei layer di data augmentation\n","        return tf.keras.Sequential([\n","            # Rotazione casuale\n","            keras.layers.RandomRotation(0.5, fill_mode='reflect'),\n","\n","            # Zoom casuale in altezza\n","            keras.layers.RandomZoom(height_factor=(-0.2, 0.7), fill_mode='nearest'),\n","\n","            # Altri tipi di augmentazioni\n","            keras.layers.RandomZoom(height_factor=(0.0, 0.0), width_factor=(-0.3, 0.3), fill_mode='nearest'),\n","            keras.layers.RandomFlip(mode=\"horizontal\"),\n","            keras.layers.RandomFlip(mode=\"vertical\"),\n","            keras.layers.RandomTranslation(height_factor=(-0.2, 0.2), width_factor=(-0.2, 0.2)),\n","\n","            keras.layers.RandomBrightness(0.3),\n","            keras_cv.layers.RandomHue(0.3, [0,255]),\n","\n","            # Aggiunta di rumore gaussiano\n","            keras.layers.GaussianNoise(0.05),\n","\n","            keras_cv.layers.RandomCutout(0.075, 0.075, fill_mode=\"gaussian_noise\"),\n","            keras_cv.layers.RandomCutout(0.075, 0.075, fill_mode=\"gaussian_noise\"),\n","            keras_cv.layers.RandomCutout(0.075, 0.075, fill_mode=\"gaussian_noise\"),\n","            keras_cv.layers.RandomCutout(0.075, 0.075, fill_mode=\"gaussian_noise\"),\n","            keras_cv.layers.RandomCutout(0.075, 0.075, fill_mode=\"gaussian_noise\"),\n","\n","            keras_cv.layers.RandomCutout(0.075, 0.075, fill_mode=\"gaussian_noise\"),\n","            keras_cv.layers.RandomCutout(0.075, 0.075, fill_mode=\"gaussian_noise\"),\n","            keras_cv.layers.RandomCutout(0.075, 0.075, fill_mode=\"gaussian_noise\"),\n","            keras_cv.layers.RandomCutout(0.075, 0.075, fill_mode=\"gaussian_noise\"),\n","            keras_cv.layers.RandomCutout(0.075, 0.075, fill_mode=\"gaussian_noise\"),\n","\n","            keras_cv.layers.RandomCutout(0.075, 0.075, fill_mode=\"gaussian_noise\"),\n","            keras_cv.layers.RandomCutout(0.075, 0.075, fill_mode=\"gaussian_noise\"),\n","            keras_cv.layers.RandomCutout(0.075, 0.075, fill_mode=\"gaussian_noise\"),\n","            keras_cv.layers.RandomCutout(0.075, 0.075, fill_mode=\"gaussian_noise\"),\n","            keras_cv.layers.RandomCutout(0.075, 0.075, fill_mode=\"gaussian_noise\"),\n","\n","            keras_cv.layers.RandomCutout(0.075, 0.075, fill_mode=\"gaussian_noise\"),\n","            keras_cv.layers.RandomCutout(0.075, 0.075, fill_mode=\"gaussian_noise\"),\n","            keras_cv.layers.RandomCutout(0.075, 0.075, fill_mode=\"gaussian_noise\"),\n","            keras_cv.layers.RandomCutout(0.075, 0.075, fill_mode=\"gaussian_noise\"),\n","            keras_cv.layers.RandomCutout(0.075, 0.075, fill_mode=\"gaussian_noise\"),\n","\n","            keras_cv.layers.RandomCutout(0.075, 0.075, fill_mode=\"gaussian_noise\"),\n","            keras_cv.layers.RandomCutout(0.075, 0.075, fill_mode=\"gaussian_noise\"),\n","            keras_cv.layers.RandomCutout(0.075, 0.075, fill_mode=\"gaussian_noise\"),\n","            keras_cv.layers.RandomCutout(0.075, 0.075, fill_mode=\"gaussian_noise\"),\n","            keras_cv.layers.RandomCutout(0.075, 0.075, fill_mode=\"gaussian_noise\"),\n","\n","            keras_cv.layers.RandomCutout(0.075, 0.075, fill_mode=\"gaussian_noise\"),\n","            keras_cv.layers.RandomCutout(0.075, 0.075, fill_mode=\"gaussian_noise\"),\n","            keras_cv.layers.RandomCutout(0.075, 0.075, fill_mode=\"gaussian_noise\"),\n","            keras_cv.layers.RandomCutout(0.075, 0.075, fill_mode=\"gaussian_noise\"),\n","            keras_cv.layers.RandomCutout(0.075, 0.075, fill_mode=\"gaussian_noise\"),\n","      ])\n","\n","\n","    def create_model(self):\n","        \"\"\"\n","        Crea e restituisce un modello con MobileNetV3Small.\n","        \"\"\"\n","        # Definisci i layer di data augmentation\n","        data_augmentation = self.get_augmentation_layer()\n","\n","        # Utilizza una rete pre-addestrata\n","        model_pretrained = tfk.applications.ConvNeXtLarge(\n","            input_shape=(96, 96, 3),\n","            include_top=False,\n","            weights='imagenet',\n","            pooling='avg'  # Pooling globale per ridurre la dimensionalità\n","        )\n","        self.model_name_pretrained = 'convnext_large'\n","\n","        print(\"number of layers:\")\n","        print(len(model_pretrained.layers))\n","\n","        # Costruisci il modello\n","        inputs = tfk.Input(shape=(96, 96, 3), name='input_layer')\n","        x = data_augmentation(inputs)\n","        x = model_pretrained(x)\n","\n","        x = tfk.layers.Dense(512, activation='relu')(x)\n","        x = tfk.layers.Dropout(0.3)(x)\n","        x = tfk.layers.Dense(256, activation='relu')(x)\n","        x = tfk.layers.Dropout(0.3)(x)\n","        '''\n","        x = tfk.layers.Dense(128, activation='relu')(x)\n","        x = tfk.layers.Dropout(0.3)(x)'''\n","        outputs = tfk.layers.Dense(8, activation='softmax', name='output_layer')(x)\n","\n","        model = tfk.Model(inputs=inputs, outputs=outputs, name='model')\n","\n","        return model\n","\n","    def train_transfer_learning(self, X_train, y_train, X_test, y_test, epochs=10, batch_size=32):\n","        \"\"\"\n","        Pre-addestra il modello con i layer congelati.\n","        \"\"\"\n","\n","        self.neural_network.get_layer(self.model_name_pretrained).trainable = False\n","\n","        # Sblocca i layer convoluzionali dal layer `fine_tune_from` in poi\n","        for i, layer in enumerate(self.neural_network.get_layer(self.model_name_pretrained).layers):\n","            layer.trainable = False\n","\n","        # Ricompila il modello (necessario dopo aver modificato i layer trainabili)\n","        self.neural_network.compile(\n","            loss=tfk.losses.CategoricalCrossentropy(),\n","            optimizer=tfk.optimizers.Lion(),\n","            metrics=['accuracy']\n","        )\n","\n","        # Callback\n","        save_every_10 = LambdaCallback(\n","            on_epoch_end=lambda epoch, logs:\n","            self.neural_network.save(f'Large/model_epoch_{epoch + 1}.keras') if (epoch + 1) % 10 == 0 else None\n","        )\n","        early_stopping = tfk.callbacks.EarlyStopping(\n","            monitor='val_accuracy',\n","            mode='max',\n","            patience=8,\n","            restore_best_weights=True\n","        )\n","\n","        # Riaddestra il modello\n","        history = self.neural_network.fit(\n","            x=X_train,\n","            y=y_train,\n","            batch_size=batch_size,\n","            epochs=epochs,\n","            shuffle=True,\n","            validation_data=(X_test, y_test),\n","            callbacks=[save_every_10, early_stopping]\n","        )\n","\n","    def train_fine_tuning(self, X_train, y_train, X_test, y_test, epochs=10, batch_size=32, fine_tune_from=50):\n","        \"\"\"\n","        Sblocca i layer selezionati e riaddestra il modello.\n","        \"\"\"\n","\n","        self.neural_network.get_layer(self.model_name_pretrained).trainable = True\n","\n","        # Sblocca i layer convoluzionali dal layer `fine_tune_from` in poi\n","        for i, layer in enumerate(self.neural_network.get_layer(self.model_name_pretrained).layers):\n","            layer.trainable = False\n","            if i > fine_tune_from:\n","              if isinstance(layer, tf.keras.layers.Conv2D) or isinstance(layer, tf.keras.layers.DepthwiseConv2D):\n","                  layer.trainable = True\n","\n","\n","        # Ricompila il modello con un learning rate più basso\n","        self.neural_network.compile(\n","            loss=tfk.losses.CategoricalCrossentropy(),\n","            optimizer=tfk.optimizers.Lion(learning_rate=1e-4),\n","            metrics=['accuracy']\n","        )\n","\n","        # Callback\n","        save_every_10 = LambdaCallback(\n","            on_epoch_end=lambda epoch, logs:\n","            self.neural_network.save(f'Large/model_epoch_{epoch + 1}.keras') if (epoch + 1) % 10 == 0 else None\n","        )\n","        early_stopping = tfk.callbacks.EarlyStopping(\n","            monitor='val_accuracy',\n","            mode='max',\n","            patience=8,\n","            restore_best_weights=True\n","        )\n","\n","        # Riaddestra il modello\n","        history = self.neural_network.fit(\n","            x=X_train,\n","            y=y_train,\n","            batch_size=batch_size,\n","            epochs=epochs,\n","            shuffle=True,\n","            validation_data=(X_test, y_test),\n","            callbacks=[save_every_10, early_stopping]\n","        )\n","\n","    def test(self, X_test, y_test):\n","        \"\"\"\n","        Valuta il modello sui dati di test X_test e le etichette y_test.\n","        \"\"\"\n","        test_loss, test_acc = self.neural_network.evaluate(X_test, y_test)\n","        print(f'Test accuracy: {test_acc}')\n","\n","    def save(self):\n","        \"\"\"\n","        Salva il modello senza i layer di data augmentation.\n","        \"\"\"\n","        self.neural_network.save('/gdrive/MyDrive/[2024-2025] AN2DL/Homework 1/Large/weights.keras')\n","\n","    def predict(self, X):\n","        \"\"\"\n","        Predice le etichette corrispondenti all'input X.\n","        \"\"\"\n","        preds = self.neural_network.predict(X)\n","        preds = np.argmax(preds, axis=1)\n","        return preds\n","\n"],"metadata":{"id":"rZiX8emjBZ3U","execution":{"iopub.status.busy":"2024-11-17T08:16:33.945144Z","iopub.execute_input":"2024-11-17T08:16:33.945566Z","iopub.status.idle":"2024-11-17T08:16:33.976064Z","shell.execute_reply.started":"2024-11-17T08:16:33.945518Z","shell.execute_reply":"2024-11-17T08:16:33.974982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = MyModel()"],"metadata":{"id":"hHk2sh_qGXLw","execution":{"iopub.status.busy":"2024-11-17T08:16:39.870156Z","iopub.execute_input":"2024-11-17T08:16:39.870560Z","iopub.status.idle":"2024-11-17T08:16:42.739919Z","shell.execute_reply.started":"2024-11-17T08:16:39.870524Z","shell.execute_reply":"2024-11-17T08:16:42.738879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_augmentation = model.get_augmentation_layer()\n","\n","# Applica la rotazione casuale\n","rotated_image = data_augmentation(X_train[6001])\n","print(y_train[6001])\n","\n","# Visualizza l'immagine originale e quella ruotata\n","plt.figure(figsize=(10, 5))\n","\n","# Mostra l'immagine ruotata\n","plt.subplot(1, 2, 1)\n","plt.imshow(X_train[6001])\n","plt.title(\"Immagine Ruotata\")\n","plt.axis('off')\n","\n","# Mostra l'immagine ruotata\n","plt.subplot(1, 2, 2)\n","plt.imshow(rotated_image / 255.0)\n","plt.title(\"Immagine Ruotata\")\n","plt.axis('off')\n","\n","plt.show()"],"metadata":{"id":"_IqqnFcq8KnX","execution":{"iopub.status.busy":"2024-11-16T21:57:01.854119Z","iopub.execute_input":"2024-11-16T21:57:01.855029Z","iopub.status.idle":"2024-11-16T21:57:02.277675Z","shell.execute_reply.started":"2024-11-16T21:57:01.854984Z","shell.execute_reply":"2024-11-16T21:57:02.276691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#model.neural_network.save('weights2.keras')"],"metadata":{"execution":{"iopub.status.busy":"2024-11-17T08:54:25.739972Z","iopub.execute_input":"2024-11-17T08:54:25.740368Z","iopub.status.idle":"2024-11-17T08:54:27.851709Z","shell.execute_reply.started":"2024-11-17T08:54:25.740330Z","shell.execute_reply":"2024-11-17T08:54:27.850767Z"},"trusted":true,"id":"ekfQWTeIf-K9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#X_test_augmented = model.get_augmentation_layer()(X_test)"],"metadata":{"id":"dcVWLb-jGRd5","execution":{"iopub.status.busy":"2024-11-15T15:22:15.155922Z","iopub.execute_input":"2024-11-15T15:22:15.156827Z","iopub.status.idle":"2024-11-15T15:22:15.826604Z","shell.execute_reply.started":"2024-11-15T15:22:15.156781Z","shell.execute_reply":"2024-11-15T15:22:15.825552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.train_transfer_learning(X_train, y_train, X_test, y_test, 20, 512)\n","#model.train_transfer_learning(X_train, y_train, X_test, y_test, 1, 512)"],"metadata":{"execution":{"iopub.status.busy":"2024-11-17T08:16:46.523493Z","iopub.execute_input":"2024-11-17T08:16:46.524448Z","iopub.status.idle":"2024-11-17T08:51:45.110003Z","shell.execute_reply.started":"2024-11-17T08:16:46.524390Z","shell.execute_reply":"2024-11-17T08:51:45.109057Z"},"trusted":true,"id":"LwHWgGdif-K9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.neural_network.save('/gdrive/My Drive/[2024-2025] AN2DL/Homework 1/Large/weights.keras')"],"metadata":{"id":"NuvYzS6frDmx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.train_fine_tuning(X_train, y_train, X_test, y_test, 50, 512, 220)\n","#model.train_fine_tuning(X_train, y_train, X_test, y_test, 1, 512, 220)"],"metadata":{"execution":{"iopub.status.busy":"2024-11-17T09:05:39.405167Z","iopub.execute_input":"2024-11-17T09:05:39.406024Z"},"trusted":true,"id":"xepIVixaf-K-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.neural_network.save('/gdrive/My Drive/[2024-2025] AN2DL/Homework 1/Large/weights2.keras')"],"metadata":{"execution":{"iopub.status.busy":"2024-11-15T15:31:12.059557Z","iopub.execute_input":"2024-11-15T15:31:12.059964Z","iopub.status.idle":"2024-11-15T15:31:12.491546Z","shell.execute_reply.started":"2024-11-15T15:31:12.059927Z","shell.execute_reply":"2024-11-15T15:31:12.490652Z"},"trusted":true,"id":"xtiWwZUsf-K-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#model.test(X_test2, y_test2)"],"metadata":{"id":"BPTK4moBCGrc","execution":{"iopub.status.busy":"2024-11-17T08:51:58.445736Z","iopub.execute_input":"2024-11-17T08:51:58.446123Z","iopub.status.idle":"2024-11-17T08:53:57.035947Z","shell.execute_reply.started":"2024-11-17T08:51:58.446085Z","shell.execute_reply":"2024-11-17T08:53:57.034984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#preds = model.predict(X_test)"],"metadata":{"id":"Syb4AHsnicdk","execution":{"iopub.status.busy":"2024-11-17T00:03:41.214203Z","iopub.execute_input":"2024-11-17T00:03:41.214640Z","iopub.status.idle":"2024-11-17T00:03:48.798006Z","shell.execute_reply.started":"2024-11-17T00:03:41.214599Z","shell.execute_reply":"2024-11-17T00:03:48.796888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n","y_true = np.argmax(y_test, axis=1)\n","y_pred = preds\n","# Genera la confusion matrix\n","cm = confusion_matrix(y_true, y_pred)\n","# Visualizza la confusion matrix con le etichette\n","disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n","disp.plot(cmap=plt.cm.Blues)\n","# Usa una mappa di colori blu\n","plt.title(\"Confusion Matrix\")\n","plt.show()\"\"\""],"metadata":{"id":"_ystjv8Wun5B","execution":{"iopub.status.busy":"2024-11-17T00:03:53.747772Z","iopub.execute_input":"2024-11-17T00:03:53.748203Z","iopub.status.idle":"2024-11-17T00:03:54.296191Z","shell.execute_reply.started":"2024-11-17T00:03:53.748161Z","shell.execute_reply":"2024-11-17T00:03:54.295221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#model.neural_network.save('/gdrive/MyDrive/weights.keras')"],"metadata":{"id":"4qMqkETBBvj0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 📊 Prepare Your SubmissionTo prepare your submission, create a `.zip` file that includes all the necessary code to run your model. It **must** include a `model.py` file with the following class:```python# file: model.pyclass Model:    def __init__(self):        \"\"\"Initialize the internal state of the model.\"\"\"    def predict(self, X):        \"\"\"Return a numpy array with the labels corresponding to the input X.\"\"\"```The next cell shows an example implementation of the `model.py` file, which includes loading model weights from the `weights.keras` file and conducting predictions on provided input data. The `.zip` file is created and downloaded in the last notebook cell.❗ Feel free to modify the method implementations to better fit your specific requirements, but please ensure that the class name and method interfaces remain unchanged."],"metadata":{"id":"RNp6pUZuddqC"}},{"cell_type":"code","source":["%%writefile '/gdrive/My Drive/[2024-2025] AN2DL/Homework 1/Large/model.py'\n","class Model2:\n","  def __init__(self):        # Carica il modello senza compilazione\n","    self.neural_network = tfk.models.load_model('weights.keras')\n","\n","  def test(self, X_test, y_test):\n","    test_loss, test_acc = self.neural_network.evaluate(X_test, y_test)\n","    print(f'Test accuracy: {test_acc}')\n","\n","  def predict(self, X):\n","    preds = self.neural_network.predict(X)\n","    if len(preds.shape) == 2:\n","      preds = np.argmax(preds, axis=1)\n","      return preds"],"metadata":{"id":"RKT4h-9xYwiT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#model2 = Model2()model2.test(X_test2, y_test2)"],"metadata":{"id":"T9qoFhPzfa6D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd Large\n","\n","from datetime import datetime\n","filename1 = f'submission_{datetime.now().strftime(\"%y%m%d_%H%M%S\")}_NOFN.zip'\n","filename2 = f'submission_{datetime.now().strftime(\"%y%m%d_%H%M%S\")}_FN.zip'\n","\n","# Add files to the zip command if needed\n","!zip {filename1} model.py weights.keras\n","!zip {filename2} model.py weights2.keras\n","\n","from google.colab import files\n","files.download(filename1)\n","files.download(filename2)"],"metadata":{"id":"s18kX1uDconq"},"execution_count":null,"outputs":[]}]}