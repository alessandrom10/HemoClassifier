{"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9915012,"sourceType":"datasetVersion","datasetId":6092801}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"markdown","source":["# Artificial Neural Networks and Deep Learning---## Homework 1: Minimal Working ExampleTo make your first submission, follow these steps:1. Create a folder named `[2024-2025] AN2DL/Homework 1` in your Google Drive.2. Upload the `training_set.npz` file to this folder.3. Upload the Jupyter notebook `Homework 1 - Minimal Working Example.ipynb`.4. Load and process the data.5. Implement and train your model.6. Submit the generated `.zip` file to Codabench."],"metadata":{"id":"nuwVgG3Vbbka"}},{"cell_type":"markdown","source":["## üåê Connect Colab to Google Drive"],"metadata":{"id":"dw_-hFm6bjY6"}},{"cell_type":"code","source":["!pip install tensorflow==2.17.0 keras==3.4.1 tensorflow-decision-forests==1.10.0 tensorflow-text==2.17.0 tf-keras==2.17.0 google keras_cv"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nSFqEXpz7qbQ","outputId":"72f12ef0-3106-4407-9253-2f7c4a46299f","execution":{"iopub.status.busy":"2024-11-17T08:12:44.211059Z","iopub.execute_input":"2024-11-17T08:12:44.211986Z","iopub.status.idle":"2024-11-17T08:14:11.913568Z","shell.execute_reply.started":"2024-11-17T08:12:44.211935Z","shell.execute_reply":"2024-11-17T08:14:11.912389Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tensorflow==2.17.0\n","  Downloading tensorflow-2.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n","Collecting keras==3.4.1\n","  Downloading keras-3.4.1-py3-none-any.whl.metadata (5.8 kB)\n","Collecting tensorflow-decision-forests==1.10.0\n","  Downloading tensorflow_decision_forests-1.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.0 kB)\n","Collecting tensorflow-text==2.17.0\n","  Downloading tensorflow_text-2.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n","Requirement already satisfied: tf-keras==2.17.0 in /usr/local/lib/python3.10/dist-packages (2.17.0)\n","Requirement already satisfied: google in /usr/local/lib/python3.10/dist-packages (2.0.3)\n","Collecting keras_cv\n","  Downloading keras_cv-0.9.0-py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (0.2.0)\n","Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (3.12.1)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (18.1.1)\n","Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (0.4.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (24.2)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (4.25.5)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (2.32.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (75.1.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (2.5.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (4.12.2)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (1.16.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (1.67.1)\n","Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (2.17.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (0.37.1)\n","Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (1.26.4)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras==3.4.1) (13.9.4)\n","Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras==3.4.1) (0.0.8)\n","Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras==3.4.1) (0.13.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from tensorflow-decision-forests==1.10.0) (2.2.2)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from tensorflow-decision-forests==1.10.0) (0.45.0)\n","Collecting wurlitzer (from tensorflow-decision-forests==1.10.0)\n","  Downloading wurlitzer-3.1.1-py3-none-any.whl.metadata (2.5 kB)\n","Collecting ydf (from tensorflow-decision-forests==1.10.0)\n","  Downloading ydf-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from google) (4.12.3)\n","Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from keras_cv) (2024.9.11)\n","Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.10/dist-packages (from keras_cv) (4.9.7)\n","Collecting keras-core (from keras_cv)\n","  Downloading keras_core-0.1.7-py3-none-any.whl.metadata (4.3 kB)\n","Requirement already satisfied: kagglehub in /usr/local/lib/python3.10/dist-packages (from keras_cv) (0.3.4)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.17.0) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.17.0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.17.0) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.17.0) (2024.8.30)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow==2.17.0) (3.7)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow==2.17.0) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow==2.17.0) (3.1.3)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->google) (2.6)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kagglehub->keras_cv) (4.66.6)\n","Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from keras-core->keras_cv) (0.1.8)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->tensorflow-decision-forests==1.10.0) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->tensorflow-decision-forests==1.10.0) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->tensorflow-decision-forests==1.10.0) (2024.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras==3.4.1) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras==3.4.1) (2.18.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (8.1.7)\n","Requirement already satisfied: immutabledict in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (4.2.0)\n","Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (2.3)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (5.9.5)\n","Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (17.0.0)\n","Requirement already satisfied: simple-parsing in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (0.1.6)\n","Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (1.13.1)\n","Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (0.10.2)\n","Requirement already satisfied: array-record>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (0.5.1)\n","Requirement already satisfied: etils>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets->keras_cv) (1.10.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets->keras_cv) (2024.10.0)\n","Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets->keras_cv) (6.4.5)\n","Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets->keras_cv) (3.21.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras==3.4.1) (0.1.2)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow==2.17.0) (3.0.2)\n","Requirement already satisfied: docstring-parser<1.0,>=0.15 in /usr/local/lib/python3.10/dist-packages (from simple-parsing->tensorflow-datasets->keras_cv) (0.16)\n","Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-metadata->tensorflow-datasets->keras_cv) (1.66.0)\n","Downloading tensorflow-2.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (601.3 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m601.3/601.3 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading keras-3.4.1-py3-none-any.whl (1.1 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tensorflow_decision_forests-1.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.5 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m15.5/15.5 MB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tensorflow_text-2.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading keras_cv-0.9.0-py3-none-any.whl (650 kB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m650.7/650.7 kB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading keras_core-0.1.7-py3-none-any.whl (950 kB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m950.8/950.8 kB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading wurlitzer-3.1.1-py3-none-any.whl (8.6 kB)\n","Downloading ydf-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.3 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m9.3/9.3 MB\u001b[0m \u001b[31m77.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: ydf, wurlitzer, keras-core, keras, tensorflow, tensorflow-text, tensorflow-decision-forests, keras_cv\n","  Attempting uninstall: keras\n","    Found existing installation: keras 3.5.0\n","    Uninstalling keras-3.5.0:\n","      Successfully uninstalled keras-3.5.0\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.17.1\n","    Uninstalling tensorflow-2.17.1:\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/gdrive')\n","%cd /gdrive/My Drive/[2024-2025] AN2DL/Homework 1"],"metadata":{"id":"y2S4GWr3Uoa8","execution":{"iopub.status.busy":"2024-11-15T11:03:22.493823Z","iopub.execute_input":"2024-11-15T11:03:22.494206Z","iopub.status.idle":"2024-11-15T11:03:22.826118Z","shell.execute_reply.started":"2024-11-15T11:03:22.494168Z","shell.execute_reply":"2024-11-15T11:03:22.825043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## ‚öôÔ∏è Import Libraries"],"metadata":{"id":"d7IqZP5Iblna"}},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras as tfk\n","from tensorflow.keras import layers as tfkl\n","\n","import numpy as np\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","\n","import matplotlib.pyplot as plt\n","import keras_cv\n","\n","import numpy as np\n","import tensorflow as tf\n","import keras_cv\n","from tensorflow import keras as tfk\n","from tensorflow.keras import layers, models, applications\n","from tensorflow.keras.callbacks import LambdaCallback\n","import random\n","import keras\n","from keras.saving import register_keras_serializable\n","\n","np.random.seed(42)\n","tf.random.set_seed(42);"],"metadata":{"id":"CO6_Ft_8T56A","execution":{"iopub.status.busy":"2024-11-17T08:14:43.509705Z","iopub.execute_input":"2024-11-17T08:14:43.510090Z","iopub.status.idle":"2024-11-17T08:14:43.516035Z","shell.execute_reply.started":"2024-11-17T08:14:43.510053Z","shell.execute_reply":"2024-11-17T08:14:43.514985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## ‚è≥ Load the Data"],"metadata":{"id":"GN_cpHlSboXV"}},{"cell_type":"code","source":["# Carica il dataset\n","data = np.load('training_set.npz')\n","X_train = data['images']\n","y_train = data['labels']\n","\n","\"\"\"# Carica il dataset\n","data2 = np.load('/kaggle/input/blood-cells/test_set.npz')\n","X_test2 = data['images']\n","y_test2 = data['labels']\"\"\"\n","\n","# Converti y in one-hot encoding\n","y_train = tf.keras.utils.to_categorical(y_train, num_classes=8)\n","#y_test2 = tf.keras.utils.to_categorical(y_test2, num_classes=8)"],"metadata":{"id":"pLaoDaG1V1Yg","execution":{"iopub.status.busy":"2024-11-17T08:14:49.626447Z","iopub.execute_input":"2024-11-17T08:14:49.627116Z","iopub.status.idle":"2024-11-17T08:14:56.162709Z","shell.execute_reply.started":"2024-11-17T08:14:49.627074Z","shell.execute_reply":"2024-11-17T08:14:56.161739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import hashlib\n","\n","def image_hash(image):\n","    image_bytes = image.tobytes()\n","    return hashlib.sha256(image_bytes).hexdigest()\n","\n","unique_images = []\n","unique_labels = []\n","duplicate_positions = set()\n","\n","seen_hashes = {}\n","\n","for i in range(len(X_train)):\n","    img_hash = image_hash(X_train[i])\n","    if img_hash not in seen_hashes:\n","        if i not in duplicate_positions:\n","            unique_images.append(X_train[i])\n","            unique_labels.append(y_train[i])\n","        seen_hashes[img_hash] = i\n","    else:\n","        duplicate_positions.add(seen_hashes[img_hash])\n","        duplicate_positions.add(i)\n","\n","X_train = [X_train[i] for i in range(len(X_train)) if i not in duplicate_positions]\n","y_train = [y_train[i] for i in range(len(y_train)) if i not in duplicate_positions]\n","\n","X_train = np.array(X_train)\n","y_train = np.array(y_train)\n"],"metadata":{"id":"rJesjkncAkkR","execution":{"iopub.status.busy":"2024-11-17T08:15:03.790978Z","iopub.execute_input":"2024-11-17T08:15:03.791994Z","iopub.status.idle":"2024-11-17T08:15:05.052590Z","shell.execute_reply.started":"2024-11-17T08:15:03.791943Z","shell.execute_reply":"2024-11-17T08:15:05.051665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# split train in training and test set\n","X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n"],"metadata":{"id":"5FxPNaJEa8RC","execution":{"iopub.status.busy":"2024-11-17T08:15:15.551402Z","iopub.execute_input":"2024-11-17T08:15:15.551828Z","iopub.status.idle":"2024-11-17T08:15:15.659219Z","shell.execute_reply.started":"2024-11-17T08:15:15.551790Z","shell.execute_reply":"2024-11-17T08:15:15.658009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_test[0]"],"metadata":{"id":"cxexV_-ENWd_","execution":{"iopub.status.busy":"2024-11-15T11:09:36.923565Z","iopub.execute_input":"2024-11-15T11:09:36.923939Z","iopub.status.idle":"2024-11-15T11:09:36.933040Z","shell.execute_reply.started":"2024-11-15T11:09:36.923904Z","shell.execute_reply":"2024-11-15T11:09:36.931916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## üõ†Ô∏è Train and Save the Model"],"metadata":{"id":"FSliIxBvbs2Q"}},{"cell_type":"code","source":["class MyModel:\n","    def __init__(self):\n","        \"\"\"\n","        Inizializza lo stato interno del modello MobileNetV3Small pre-addestrato.\n","        \"\"\"\n","        self.neural_network = self.create_model()\n","\n","    def get_augmentation_layer(self):\n","        # Definizione dei layer di data augmentation\n","        return tf.keras.Sequential([\n","            # Rotazione casuale\n","            keras.layers.RandomRotation(0.5, fill_mode='reflect'),\n","\n","            # Zoom casuale in altezza\n","            keras.layers.RandomZoom(height_factor=(-0.2, 0.7), fill_mode='nearest'),\n","\n","            # Altri tipi di augmentazioni\n","            keras.layers.RandomZoom(height_factor=(0.0, 0.0), width_factor=(-0.3, 0.3), fill_mode='nearest'),\n","            keras.layers.RandomFlip(mode=\"horizontal\"),\n","            keras.layers.RandomFlip(mode=\"vertical\"),\n","            keras.layers.RandomTranslation(height_factor=(-0.2, 0.2), width_factor=(-0.2, 0.2)),\n","\n","            keras.layers.RandomBrightness(0.3),\n","            keras_cv.layers.RandomHue(0.3, [0,255]),\n","\n","            # Aggiunta di rumore gaussiano\n","            keras.layers.GaussianNoise(0.05),\n","\n","            keras_cv.layers.RandomCutout(0.075, 0.075, fill_mode=\"gaussian_noise\"),\n","            keras_cv.layers.RandomCutout(0.075, 0.075, fill_mode=\"gaussian_noise\"),\n","            keras_cv.layers.RandomCutout(0.075, 0.075, fill_mode=\"gaussian_noise\"),\n","            keras_cv.layers.RandomCutout(0.075, 0.075, fill_mode=\"gaussian_noise\"),\n","            keras_cv.layers.RandomCutout(0.075, 0.075, fill_mode=\"gaussian_noise\"),\n","\n","            keras_cv.layers.RandomCutout(0.075, 0.075, fill_mode=\"gaussian_noise\"),\n","            keras_cv.layers.RandomCutout(0.075, 0.075, fill_mode=\"gaussian_noise\"),\n","            keras_cv.layers.RandomCutout(0.075, 0.075, fill_mode=\"gaussian_noise\"),\n","            keras_cv.layers.RandomCutout(0.075, 0.075, fill_mode=\"gaussian_noise\"),\n","            keras_cv.layers.RandomCutout(0.075, 0.075, fill_mode=\"gaussian_noise\"),\n","\n","            keras_cv.layers.RandomCutout(0.075, 0.075, fill_mode=\"gaussian_noise\"),\n","            keras_cv.layers.RandomCutout(0.075, 0.075, fill_mode=\"gaussian_noise\"),\n","            keras_cv.layers.RandomCutout(0.075, 0.075, fill_mode=\"gaussian_noise\"),\n","            keras_cv.layers.RandomCutout(0.075, 0.075, fill_mode=\"gaussian_noise\"),\n","            keras_cv.layers.RandomCutout(0.075, 0.075, fill_mode=\"gaussian_noise\"),\n","\n","            keras_cv.layers.RandomCutout(0.075, 0.075, fill_mode=\"gaussian_noise\"),\n","            keras_cv.layers.RandomCutout(0.075, 0.075, fill_mode=\"gaussian_noise\"),\n","            keras_cv.layers.RandomCutout(0.075, 0.075, fill_mode=\"gaussian_noise\"),\n","            keras_cv.layers.RandomCutout(0.075, 0.075, fill_mode=\"gaussian_noise\"),\n","            keras_cv.layers.RandomCutout(0.075, 0.075, fill_mode=\"gaussian_noise\"),\n","\n","            keras_cv.layers.RandomCutout(0.075, 0.075, fill_mode=\"gaussian_noise\"),\n","            keras_cv.layers.RandomCutout(0.075, 0.075, fill_mode=\"gaussian_noise\"),\n","            keras_cv.layers.RandomCutout(0.075, 0.075, fill_mode=\"gaussian_noise\"),\n","            keras_cv.layers.RandomCutout(0.075, 0.075, fill_mode=\"gaussian_noise\"),\n","            keras_cv.layers.RandomCutout(0.075, 0.075, fill_mode=\"gaussian_noise\"),\n","\n","            keras_cv.layers.RandomCutout(0.075, 0.075, fill_mode=\"gaussian_noise\"),\n","            keras_cv.layers.RandomCutout(0.075, 0.075, fill_mode=\"gaussian_noise\"),\n","            keras_cv.layers.RandomCutout(0.075, 0.075, fill_mode=\"gaussian_noise\"),\n","            keras_cv.layers.RandomCutout(0.075, 0.075, fill_mode=\"gaussian_noise\"),\n","            keras_cv.layers.RandomCutout(0.075, 0.075, fill_mode=\"gaussian_noise\"),\n","      ])\n","\n","\n","    def create_model(self):\n","        \"\"\"\n","        Crea e restituisce un modello con MobileNetV3Small.\n","        \"\"\"\n","        # Definisci i layer di data augmentation\n","        data_augmentation = self.get_augmentation_layer()\n","\n","        # Utilizza una rete pre-addestrata\n","        model_pretrained = tfk.applications.ConvNeXtLarge(\n","            input_shape=(96, 96, 3),\n","            include_top=False,\n","            weights='imagenet',\n","            pooling='avg'  # Pooling globale per ridurre la dimensionalit√†\n","        )\n","        self.model_name_pretrained = 'convnext_large'\n","\n","        print(\"number of layers:\")\n","        print(len(model_pretrained.layers))\n","\n","        # Costruisci il modello\n","        inputs = tfk.Input(shape=(96, 96, 3), name='input_layer')\n","        x = data_augmentation(inputs)\n","        x = model_pretrained(x)\n","\n","        x = tfk.layers.Dense(512, activation='relu')(x)\n","        x = tfk.layers.Dropout(0.3)(x)\n","        x = tfk.layers.Dense(256, activation='relu')(x)\n","        x = tfk.layers.Dropout(0.3)(x)\n","        '''\n","        x = tfk.layers.Dense(128, activation='relu')(x)\n","        x = tfk.layers.Dropout(0.3)(x)'''\n","        outputs = tfk.layers.Dense(8, activation='softmax', name='output_layer')(x)\n","\n","        model = tfk.Model(inputs=inputs, outputs=outputs, name='model')\n","\n","        return model\n","\n","    def train_transfer_learning(self, X_train, y_train, X_test, y_test, epochs=10, batch_size=32):\n","        \"\"\"\n","        Pre-addestra il modello con i layer congelati.\n","        \"\"\"\n","\n","        self.neural_network.get_layer(self.model_name_pretrained).trainable = False\n","\n","        # Sblocca i layer convoluzionali dal layer `fine_tune_from` in poi\n","        for i, layer in enumerate(self.neural_network.get_layer(self.model_name_pretrained).layers):\n","            layer.trainable = False\n","\n","        # Ricompila il modello (necessario dopo aver modificato i layer trainabili)\n","        self.neural_network.compile(\n","            loss=tfk.losses.CategoricalCrossentropy(),\n","            optimizer=tfk.optimizers.Lion(),\n","            metrics=['accuracy']\n","        )\n","\n","        # Callback\n","        save_every_10 = LambdaCallback(\n","            on_epoch_end=lambda epoch, logs:\n","            self.neural_network.save(f'Large/model_epoch_{epoch + 1}.keras') if (epoch + 1) % 10 == 0 else None\n","        )\n","        early_stopping = tfk.callbacks.EarlyStopping(\n","            monitor='val_accuracy',\n","            mode='max',\n","            patience=8,\n","            restore_best_weights=True\n","        )\n","\n","        # Riaddestra il modello\n","        history = self.neural_network.fit(\n","            x=X_train,\n","            y=y_train,\n","            batch_size=batch_size,\n","            epochs=epochs,\n","            shuffle=True,\n","            validation_data=(X_test, y_test),\n","            callbacks=[save_every_10, early_stopping]\n","        )\n","\n","    def train_fine_tuning(self, X_train, y_train, X_test, y_test, epochs=10, batch_size=32, fine_tune_from=50):\n","        \"\"\"\n","        Sblocca i layer selezionati e riaddestra il modello.\n","        \"\"\"\n","\n","        self.neural_network.get_layer(self.model_name_pretrained).trainable = True\n","\n","        # Sblocca i layer convoluzionali dal layer `fine_tune_from` in poi\n","        for i, layer in enumerate(self.neural_network.get_layer(self.model_name_pretrained).layers):\n","            layer.trainable = False\n","            if i > fine_tune_from:\n","              if isinstance(layer, tf.keras.layers.Conv2D) or isinstance(layer, tf.keras.layers.DepthwiseConv2D):\n","                  layer.trainable = True\n","\n","\n","        # Ricompila il modello con un learning rate pi√π basso\n","        self.neural_network.compile(\n","            loss=tfk.losses.CategoricalCrossentropy(),\n","            optimizer=tfk.optimizers.Lion(learning_rate=1e-4),\n","            metrics=['accuracy']\n","        )\n","\n","        # Callback\n","        save_every_10 = LambdaCallback(\n","            on_epoch_end=lambda epoch, logs:\n","            self.neural_network.save(f'Large/model_epoch_{epoch + 1}.keras') if (epoch + 1) % 10 == 0 else None\n","        )\n","        early_stopping = tfk.callbacks.EarlyStopping(\n","            monitor='val_accuracy',\n","            mode='max',\n","            patience=8,\n","            restore_best_weights=True\n","        )\n","\n","        # Riaddestra il modello\n","        history = self.neural_network.fit(\n","            x=X_train,\n","            y=y_train,\n","            batch_size=batch_size,\n","            epochs=epochs,\n","            shuffle=True,\n","            validation_data=(X_test, y_test),\n","            callbacks=[save_every_10, early_stopping]\n","        )\n","\n","    def test(self, X_test, y_test):\n","        \"\"\"\n","        Valuta il modello sui dati di test X_test e le etichette y_test.\n","        \"\"\"\n","        test_loss, test_acc = self.neural_network.evaluate(X_test, y_test)\n","        print(f'Test accuracy: {test_acc}')\n","\n","    def save(self):\n","        \"\"\"\n","        Salva il modello senza i layer di data augmentation.\n","        \"\"\"\n","        self.neural_network.save('/gdrive/MyDrive/[2024-2025] AN2DL/Homework 1/Large/weights.keras')\n","\n","    def predict(self, X):\n","        \"\"\"\n","        Predice le etichette corrispondenti all'input X.\n","        \"\"\"\n","        preds = self.neural_network.predict(X)\n","        preds = np.argmax(preds, axis=1)\n","        return preds\n","\n"],"metadata":{"id":"rZiX8emjBZ3U","execution":{"iopub.status.busy":"2024-11-17T08:16:33.945144Z","iopub.execute_input":"2024-11-17T08:16:33.945566Z","iopub.status.idle":"2024-11-17T08:16:33.976064Z","shell.execute_reply.started":"2024-11-17T08:16:33.945518Z","shell.execute_reply":"2024-11-17T08:16:33.974982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = MyModel()"],"metadata":{"id":"hHk2sh_qGXLw","execution":{"iopub.status.busy":"2024-11-17T08:16:39.870156Z","iopub.execute_input":"2024-11-17T08:16:39.870560Z","iopub.status.idle":"2024-11-17T08:16:42.739919Z","shell.execute_reply.started":"2024-11-17T08:16:39.870524Z","shell.execute_reply":"2024-11-17T08:16:42.738879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_augmentation = model.get_augmentation_layer()\n","\n","# Applica la rotazione casuale\n","rotated_image = data_augmentation(X_train[6001])\n","print(y_train[6001])\n","\n","# Visualizza l'immagine originale e quella ruotata\n","plt.figure(figsize=(10, 5))\n","\n","# Mostra l'immagine ruotata\n","plt.subplot(1, 2, 1)\n","plt.imshow(X_train[6001])\n","plt.title(\"Immagine Ruotata\")\n","plt.axis('off')\n","\n","# Mostra l'immagine ruotata\n","plt.subplot(1, 2, 2)\n","plt.imshow(rotated_image / 255.0)\n","plt.title(\"Immagine Ruotata\")\n","plt.axis('off')\n","\n","plt.show()"],"metadata":{"id":"_IqqnFcq8KnX","execution":{"iopub.status.busy":"2024-11-16T21:57:01.854119Z","iopub.execute_input":"2024-11-16T21:57:01.855029Z","iopub.status.idle":"2024-11-16T21:57:02.277675Z","shell.execute_reply.started":"2024-11-16T21:57:01.854984Z","shell.execute_reply":"2024-11-16T21:57:02.276691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#model.neural_network.save('weights2.keras')"],"metadata":{"execution":{"iopub.status.busy":"2024-11-17T08:54:25.739972Z","iopub.execute_input":"2024-11-17T08:54:25.740368Z","iopub.status.idle":"2024-11-17T08:54:27.851709Z","shell.execute_reply.started":"2024-11-17T08:54:25.740330Z","shell.execute_reply":"2024-11-17T08:54:27.850767Z"},"trusted":true,"id":"ekfQWTeIf-K9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#X_test_augmented = model.get_augmentation_layer()(X_test)"],"metadata":{"id":"dcVWLb-jGRd5","execution":{"iopub.status.busy":"2024-11-15T15:22:15.155922Z","iopub.execute_input":"2024-11-15T15:22:15.156827Z","iopub.status.idle":"2024-11-15T15:22:15.826604Z","shell.execute_reply.started":"2024-11-15T15:22:15.156781Z","shell.execute_reply":"2024-11-15T15:22:15.825552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.train_transfer_learning(X_train, y_train, X_test, y_test, 20, 512)\n","#model.train_transfer_learning(X_train, y_train, X_test, y_test, 1, 512)"],"metadata":{"execution":{"iopub.status.busy":"2024-11-17T08:16:46.523493Z","iopub.execute_input":"2024-11-17T08:16:46.524448Z","iopub.status.idle":"2024-11-17T08:51:45.110003Z","shell.execute_reply.started":"2024-11-17T08:16:46.524390Z","shell.execute_reply":"2024-11-17T08:51:45.109057Z"},"trusted":true,"id":"LwHWgGdif-K9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.neural_network.save('/gdrive/My Drive/[2024-2025] AN2DL/Homework 1/Large/weights.keras')"],"metadata":{"id":"NuvYzS6frDmx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.train_fine_tuning(X_train, y_train, X_test, y_test, 50, 512, 220)\n","#model.train_fine_tuning(X_train, y_train, X_test, y_test, 1, 512, 220)"],"metadata":{"execution":{"iopub.status.busy":"2024-11-17T09:05:39.405167Z","iopub.execute_input":"2024-11-17T09:05:39.406024Z"},"trusted":true,"id":"xepIVixaf-K-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.neural_network.save('/gdrive/My Drive/[2024-2025] AN2DL/Homework 1/Large/weights2.keras')"],"metadata":{"execution":{"iopub.status.busy":"2024-11-15T15:31:12.059557Z","iopub.execute_input":"2024-11-15T15:31:12.059964Z","iopub.status.idle":"2024-11-15T15:31:12.491546Z","shell.execute_reply.started":"2024-11-15T15:31:12.059927Z","shell.execute_reply":"2024-11-15T15:31:12.490652Z"},"trusted":true,"id":"xtiWwZUsf-K-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#model.test(X_test2, y_test2)"],"metadata":{"id":"BPTK4moBCGrc","execution":{"iopub.status.busy":"2024-11-17T08:51:58.445736Z","iopub.execute_input":"2024-11-17T08:51:58.446123Z","iopub.status.idle":"2024-11-17T08:53:57.035947Z","shell.execute_reply.started":"2024-11-17T08:51:58.446085Z","shell.execute_reply":"2024-11-17T08:53:57.034984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#preds = model.predict(X_test)"],"metadata":{"id":"Syb4AHsnicdk","execution":{"iopub.status.busy":"2024-11-17T00:03:41.214203Z","iopub.execute_input":"2024-11-17T00:03:41.214640Z","iopub.status.idle":"2024-11-17T00:03:48.798006Z","shell.execute_reply.started":"2024-11-17T00:03:41.214599Z","shell.execute_reply":"2024-11-17T00:03:48.796888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n","y_true = np.argmax(y_test, axis=1)\n","y_pred = preds\n","# Genera la confusion matrix\n","cm = confusion_matrix(y_true, y_pred)\n","# Visualizza la confusion matrix con le etichette\n","disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n","disp.plot(cmap=plt.cm.Blues)\n","# Usa una mappa di colori blu\n","plt.title(\"Confusion Matrix\")\n","plt.show()\"\"\""],"metadata":{"id":"_ystjv8Wun5B","execution":{"iopub.status.busy":"2024-11-17T00:03:53.747772Z","iopub.execute_input":"2024-11-17T00:03:53.748203Z","iopub.status.idle":"2024-11-17T00:03:54.296191Z","shell.execute_reply.started":"2024-11-17T00:03:53.748161Z","shell.execute_reply":"2024-11-17T00:03:54.295221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#model.neural_network.save('/gdrive/MyDrive/weights.keras')"],"metadata":{"id":"4qMqkETBBvj0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## üìä Prepare Your SubmissionTo prepare your submission, create a `.zip` file that includes all the necessary code to run your model. It **must** include a `model.py` file with the following class:```python# file: model.pyclass Model:    def __init__(self):        \"\"\"Initialize the internal state of the model.\"\"\"    def predict(self, X):        \"\"\"Return a numpy array with the labels corresponding to the input X.\"\"\"```The next cell shows an example implementation of the `model.py` file, which includes loading model weights from the `weights.keras` file and conducting predictions on provided input data. The `.zip` file is created and downloaded in the last notebook cell.‚ùó Feel free to modify the method implementations to better fit your specific requirements, but please ensure that the class name and method interfaces remain unchanged."],"metadata":{"id":"RNp6pUZuddqC"}},{"cell_type":"code","source":["%%writefile '/gdrive/My Drive/[2024-2025] AN2DL/Homework 1/Large/model.py'\n","class Model2:\n","  def __init__(self):        # Carica il modello senza compilazione\n","    self.neural_network = tfk.models.load_model('weights.keras')\n","\n","  def test(self, X_test, y_test):\n","    test_loss, test_acc = self.neural_network.evaluate(X_test, y_test)\n","    print(f'Test accuracy: {test_acc}')\n","\n","  def predict(self, X):\n","    preds = self.neural_network.predict(X)\n","    if len(preds.shape) == 2:\n","      preds = np.argmax(preds, axis=1)\n","      return preds"],"metadata":{"id":"RKT4h-9xYwiT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#model2 = Model2()model2.test(X_test2, y_test2)"],"metadata":{"id":"T9qoFhPzfa6D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd Large\n","\n","from datetime import datetime\n","filename1 = f'submission_{datetime.now().strftime(\"%y%m%d_%H%M%S\")}_NOFN.zip'\n","filename2 = f'submission_{datetime.now().strftime(\"%y%m%d_%H%M%S\")}_FN.zip'\n","\n","# Add files to the zip command if needed\n","!zip {filename1} model.py weights.keras\n","!zip {filename2} model.py weights2.keras\n","\n","from google.colab import files\n","files.download(filename1)\n","files.download(filename2)"],"metadata":{"id":"s18kX1uDconq"},"execution_count":null,"outputs":[]}]}