{"cells":[{"cell_type":"markdown","metadata":{"id":"nuwVgG3Vbbka"},"source":["## **Introduction**\n","In this notebook, we will build and train a neural network for classifying blood cells using ResNet, a deep residual network architecture.\n","\n","This project demonstrates the application of deep learning to medical imaging and classification tasks.\n"]},{"cell_type":"markdown","metadata":{"id":"dw_-hFm6bjY6"},"source":["## üöÄ Setting Up the Environment: Installing Packages and Connecting to Google Drive\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":85783,"status":"ok","timestamp":1732437296384,"user":{"displayName":"Alessandro","userId":"13573195732524414409"},"user_tz":-60},"id":"nSFqEXpz7qbQ","outputId":"8c44dc82-191d-48d3-bd90-10e4d168710b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tensorflow==2.17.0\n","  Downloading tensorflow-2.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n","Collecting keras==3.4.1\n","  Downloading keras-3.4.1-py3-none-any.whl.metadata (5.8 kB)\n","Collecting tensorflow-decision-forests==1.10.0\n","  Downloading tensorflow_decision_forests-1.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.0 kB)\n","Collecting tensorflow-text==2.17.0\n","  Downloading tensorflow_text-2.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n","Requirement already satisfied: tf-keras==2.17.0 in /usr/local/lib/python3.10/dist-packages (2.17.0)\n","Collecting keras_cv\n","  Downloading keras_cv-0.9.0-py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (0.2.0)\n","Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (3.12.1)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (18.1.1)\n","Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (0.4.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (24.2)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (4.25.5)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (2.32.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (75.1.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (2.5.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (4.12.2)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (1.16.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (1.68.0)\n","Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (2.17.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (0.37.1)\n","Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (1.26.4)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras==3.4.1) (13.9.4)\n","Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras==3.4.1) (0.0.8)\n","Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras==3.4.1) (0.13.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from tensorflow-decision-forests==1.10.0) (2.2.2)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from tensorflow-decision-forests==1.10.0) (0.45.0)\n","Collecting wurlitzer (from tensorflow-decision-forests==1.10.0)\n","  Downloading wurlitzer-3.1.1-py3-none-any.whl.metadata (2.5 kB)\n","Collecting ydf (from tensorflow-decision-forests==1.10.0)\n","  Downloading ydf-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n","Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from keras_cv) (2024.9.11)\n","Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.10/dist-packages (from keras_cv) (4.9.7)\n","Collecting keras-core (from keras_cv)\n","  Downloading keras_core-0.1.7-py3-none-any.whl.metadata (4.3 kB)\n","Requirement already satisfied: kagglehub in /usr/local/lib/python3.10/dist-packages (from keras_cv) (0.3.4)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.17.0) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.17.0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.17.0) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.17.0) (2024.8.30)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow==2.17.0) (3.7)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow==2.17.0) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow==2.17.0) (3.1.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kagglehub->keras_cv) (4.66.6)\n","Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from keras-core->keras_cv) (0.1.8)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->tensorflow-decision-forests==1.10.0) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->tensorflow-decision-forests==1.10.0) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->tensorflow-decision-forests==1.10.0) (2024.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras==3.4.1) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras==3.4.1) (2.18.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (8.1.7)\n","Requirement already satisfied: immutabledict in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (4.2.1)\n","Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (2.3)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (5.9.5)\n","Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (17.0.0)\n","Requirement already satisfied: simple-parsing in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (0.1.6)\n","Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (1.13.1)\n","Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (0.10.2)\n","Requirement already satisfied: array-record>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (0.5.1)\n","Requirement already satisfied: etils>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets->keras_cv) (1.10.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets->keras_cv) (2024.10.0)\n","Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets->keras_cv) (6.4.5)\n","Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets->keras_cv) (3.21.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras==3.4.1) (0.1.2)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow==2.17.0) (3.0.2)\n","Requirement already satisfied: docstring-parser<1.0,>=0.15 in /usr/local/lib/python3.10/dist-packages (from simple-parsing->tensorflow-datasets->keras_cv) (0.16)\n","Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-metadata->tensorflow-datasets->keras_cv) (1.66.0)\n","Downloading tensorflow-2.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (601.3 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m601.3/601.3 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading keras-3.4.1-py3-none-any.whl (1.1 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tensorflow_decision_forests-1.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.5 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m15.5/15.5 MB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tensorflow_text-2.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading keras_cv-0.9.0-py3-none-any.whl (650 kB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m650.7/650.7 kB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading keras_core-0.1.7-py3-none-any.whl (950 kB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m950.8/950.8 kB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading wurlitzer-3.1.1-py3-none-any.whl (8.6 kB)\n","Downloading ydf-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.3 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m9.3/9.3 MB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: ydf, wurlitzer, keras-core, keras, tensorflow, tensorflow-text, tensorflow-decision-forests, keras_cv\n","  Attempting uninstall: keras\n","    Found existing installation: keras 3.5.0\n","    Uninstalling keras-3.5.0:\n","      Successfully uninstalled keras-3.5.0\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.17.1\n","    Uninstalling tensorflow-2.17.1:\n","      Successfully uninstalled tensorflow-2.17.1\n","Successfully installed keras-3.4.1 keras-core-0.1.7 keras_cv-0.9.0 tensorflow-2.17.0 tensorflow-decision-forests-1.10.0 tensorflow-text-2.17.0 wurlitzer-3.1.1 ydf-0.8.0\n"]}],"source":["!pip install tensorflow==2.17.0 keras==3.4.1 tensorflow-decision-forests==1.10.0 tensorflow-text==2.17.0 tf-keras==2.17.0 keras_cv"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CO6_Ft_8T56A"},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras as tfk\n","from tensorflow.keras import layers as tfkl\n","import keras_cv\n","\n","import numpy as np\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","\n","\"\"\"np.random.seed(42)\n","tf.random.set_seed(42);\"\"\"\n","\n","np.random.seed(11)\n","tf.random.set_seed(11);"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17344,"status":"ok","timestamp":1732437330962,"user":{"displayName":"Alessandro","userId":"13573195732524414409"},"user_tz":-60},"id":"3wAm_kLONkFh","outputId":"34d58e34-4d0b-4634-a21f-4349a4ac3542"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /gdrive\n","/gdrive/My Drive/[2024-2025] AN2DL/Homework 1/Base_3\n"]}],"source":["from google.colab import drive\n","drive.mount('/gdrive')\n","%cd /gdrive/My Drive/[2024-2025] AN2DL/Homework 1/Base_3"]},{"cell_type":"markdown","metadata":{"id":"GN_cpHlSboXV"},"source":["## ‚è≥ Load the Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pLaoDaG1V1Yg"},"outputs":[],"source":["# Load the dataset\n","#data = np.load('training_set.npz')\n","#data = np.load('dataset_augmented_10k.npz')\n","data = np.load('dataset_augmented_default.npz')\n","x_train = data['images']\n","y_train = data['labels']\n","\n","data_original = np.load('training_set.npz')\n","x_test = data_original['images']\n","y_test = data_original['labels']"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1239,"status":"ok","timestamp":1732437446306,"user":{"displayName":"Alessandro","userId":"13573195732524414409"},"user_tz":-60},"id":"rJesjkncAkkR","outputId":"2426dd4d-7fa8-4990-94b1-fdaee4888a03"},"outputs":[{"output_type":"stream","name":"stdout","text":["Initial length is 20776 and 20776\n","Len: 20776\n"," Shape: (20776, 96, 96, 3)\n","\n","Len: 20776\n"," Shape: (20776, 8)\n","\n","Len: 11943\n"," Shape: (11943, 96, 96, 3)\n","\n","Len: 11943\n"," Shape: (11943, 1)\n","\n"]}],"source":["import hashlib\n","\n","# Get the hash of a certain image\n","def image_hash(image):\n","  image_bytes = image.tobytes()\n","  return hashlib.sha256(image_bytes).hexdigest()\n","\n","print(f\"Initial length is {len(x_train)} and {len(y_train)}\")\n","\n","# Remove all duplicates\n","def remove_duplicates(x_train, y_train):\n","  unique_images = []\n","  unique_labels = []\n","  duplicate_positions = set()\n","\n","  seen_hashes = {}\n","\n","  for i in range(len(x_train)):\n","      img_hash = image_hash(x_train[i])\n","      if img_hash not in seen_hashes:\n","        if i not in duplicate_positions:\n","          unique_images.append(x_train[i])\n","          unique_labels.append(y_train[i])\n","        seen_hashes[img_hash] = i\n","      else:\n","        duplicate_positions.add(seen_hashes[img_hash])\n","        duplicate_positions.add(i)\n","\n","  x_train = [x_train[i] for i in range(len(x_train)) if i not in duplicate_positions]\n","  y_train = [y_train[i] for i in range(len(y_train)) if i not in duplicate_positions]\n","\n","  x_train = np.array(x_train)\n","  y_train = np.array(y_train)\n","\n","  return x_train, y_train\n","\n","#x_train, y_train = remove_duplicates(x_train, y_train)\n","\n","x_test, y_test = remove_duplicates(x_test, y_test)\n","\n","print(f\"Len: {len(x_train)}\\n Shape: {x_train.shape}\\n\")\n","print(f\"Len: {len(y_train)}\\n Shape: {y_train.shape}\\n\")\n","print(f\"Len: {len(x_test)}\\n Shape: {x_test.shape}\\n\")\n","print(f\"Len: {len(y_test)}\\n Shape: {y_test.shape}\\n\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":104},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1732437446306,"user":{"displayName":"Alessandro","userId":"13573195732524414409"},"user_tz":-60},"id":"_yI2adyA44-y","outputId":"d652932d-b5aa-423f-ea7c-51fe708d6178"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'# Define a basic set of transformations 1\\ndata_augmentation = keras_cv.layers.Augmenter(\\n  layers = [\\n    layers.RandomFlip(\"horizontal_and_vertical\"),\\n    layers.RandomRotation(0.2),\\n    layers.RandomZoom(0.1),\\n    layers.RandomTranslation(0.1, 0.1),\\n    layers.RandomContrast(0.2),\\n  ]\\n)\\n\\n# Extract unique classes and their counts\\nunique, counts = np.unique(y_train, return_counts=True)\\nclass_counts = dict(zip(unique, counts))\\nprint(\"Original distribution:\", class_counts)\\n\\n# Maximum number of samples for a class\\nmax_samples = max(class_counts.values())\\n\\ndef make_balanced_with_augmented(x_train, y_train):\\n\\n  # New balanced dataset\\n  x_balanced = []\\n  y_balanced = []\\n\\n  # Oversampling for each class\\n  for cls in class_counts:\\n    # Filter samples for the current class\\n    x_class = x_train[np.where(y_train == cls)[0]]\\n    y_class = y_train[y_train == cls]\\n\\n    # Calculate the number of samples to add\\n    samples_to_add = max_samples - len(x_class)\\n\\n    if samples_to_add > 0:\\n      # Augment the samples to add\\n      augmented_images = []\\n      for _ in range(samples_to_add):\\n        augmented_image = data_augmentation(x_class[np.random.randint(len(x_class))][np.newaxis, ...])\\n        augmented_images.append(augmented_image.numpy()[0])\\n\\n      # Add the original and augmented samples to the balanced dataset\\n      x_balanced.append(np.concatenate([x_class, np.array(augmented_images)]))\\n      y_balanced.append(np.concatenate([y_class, np.full(samples_to_add, cls)]))\\n    else:\\n      # Add the original samples to the balanced dataset (if no oversampling is needed)\\n      x_balanced.append(x_class)\\n      y_balanced.append(y_class)\\n\\n  # Concatenate the balanced dataset\\n  x_train = np.concatenate(x_balanced)\\n  y_train = np.concatenate(y_balanced)\\n\\n  return x_train, y_train\\n\\nx_train, y_train = make_balanced_with_augmented(x_train, y_train)\\n\\n# Check the new distribution\\nunique_balanced, counts_balanced = np.unique(y_train, return_counts=True)\\nclass_counts_balanced = dict(zip(unique_balanced, counts_balanced))\\nprint(\"Balanced distribution of classes:\", class_counts_balanced)\\nprint(f\"New total number of sample is {len(x_train)}\")'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":10}],"source":["from keras import layers\n","\n","\"\"\"# Define a basic set of transformations 1\n","data_augmentation = keras_cv.layers.Augmenter(\n","  layers = [\n","    layers.RandomFlip(\"horizontal_and_vertical\"),\n","    layers.RandomRotation(0.2),\n","    layers.RandomZoom(0.1),\n","    layers.RandomTranslation(0.1, 0.1),\n","    layers.RandomContrast(0.2),\n","  ]\n",")\n","\n","# Extract unique classes and their counts\n","unique, counts = np.unique(y_train, return_counts=True)\n","class_counts = dict(zip(unique, counts))\n","print(\"Original distribution:\", class_counts)\n","\n","# Maximum number of samples for a class\n","max_samples = max(class_counts.values())\n","\n","def make_balanced_with_augmented(x_train, y_train):\n","\n","  # New balanced dataset\n","  x_balanced = []\n","  y_balanced = []\n","\n","  # Oversampling for each class\n","  for cls in class_counts:\n","    # Filter samples for the current class\n","    x_class = x_train[np.where(y_train == cls)[0]]\n","    y_class = y_train[y_train == cls]\n","\n","    # Calculate the number of samples to add\n","    samples_to_add = max_samples - len(x_class)\n","\n","    if samples_to_add > 0:\n","      # Augment the samples to add\n","      augmented_images = []\n","      for _ in range(samples_to_add):\n","        augmented_image = data_augmentation(x_class[np.random.randint(len(x_class))][np.newaxis, ...])\n","        augmented_images.append(augmented_image.numpy()[0])\n","\n","      # Add the original and augmented samples to the balanced dataset\n","      x_balanced.append(np.concatenate([x_class, np.array(augmented_images)]))\n","      y_balanced.append(np.concatenate([y_class, np.full(samples_to_add, cls)]))\n","    else:\n","      # Add the original samples to the balanced dataset (if no oversampling is needed)\n","      x_balanced.append(x_class)\n","      y_balanced.append(y_class)\n","\n","  # Concatenate the balanced dataset\n","  x_train = np.concatenate(x_balanced)\n","  y_train = np.concatenate(y_balanced)\n","\n","  return x_train, y_train\n","\n","x_train, y_train = make_balanced_with_augmented(x_train, y_train)\n","\n","# Check the new distribution\n","unique_balanced, counts_balanced = np.unique(y_train, return_counts=True)\n","class_counts_balanced = dict(zip(unique_balanced, counts_balanced))\n","print(\"Balanced distribution of classes:\", class_counts_balanced)\n","print(f\"New total number of sample is {len(x_train)}\")\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1732437446306,"user":{"displayName":"Alessandro","userId":"13573195732524414409"},"user_tz":-60},"id":"KIA7fJLg44-y","colab":{"base_uri":"https://localhost:8080/"},"outputId":"7c8a936e-fec5-4367-bdcf-e932feefc89b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Len: 20776\n"," Shape: (20776, 96, 96, 3)\n","\n","Len: 20776\n"," Shape: (20776, 8)\n","\n","Len: 11943\n"," Shape: (11943, 96, 96, 3)\n","\n","Len: 11943\n"," Shape: (11943, 8)\n","\n"]}],"source":["# Converti y in one-hot encoding\n","#y_train = tf.keras.utils.to_categorical(y_train, num_classes=8)\n","#y_train = tf.keras.utils.to_categorical(y_train, num_classes=8)\n","#y_test2 = tf.keras.utils.to_categorical(y_test2, num_classes=8)\n","\n","y_test = tf.keras.utils.to_categorical(y_test, num_classes=8)\n","\n","print(f\"Len: {len(x_train)}\\n Shape: {x_train.shape}\\n\")\n","print(f\"Len: {len(y_train)}\\n Shape: {y_train.shape}\\n\")\n","print(f\"Len: {len(x_test)}\\n Shape: {x_test.shape}\\n\")\n","print(f\"Len: {len(y_test)}\\n Shape: {y_test.shape}\\n\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5FxPNaJEa8RC"},"outputs":[],"source":["# split train in training and test set\n","#x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.1, random_state=42)\n","#x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.1, random_state=99)\n","### x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.1, random_state=11)"]},{"cell_type":"markdown","metadata":{"id":"Vm3FHPFD44-z"},"source":["# Preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1732437446306,"user":{"displayName":"Alessandro","userId":"13573195732524414409"},"user_tz":-60},"id":"Wf3_Ii2J44-z","colab":{"base_uri":"https://localhost:8080/","height":70},"outputId":"ab1918ef-b08c-44db-9ce3-2019ef247331"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'def augment(images, labels):\\n  augmenter = keras_cv.layers.Augmenter(\\n    layers = [\\n      keras_cv.layers.RandomFlip(\\n          mode=\"horizontal_and_vertical\"\\n      ),\\n      keras_cv.layers.RandomRotation(\\n          factor=0.2,\\n          fill_mode=\\'nearest\\'\\n      ),\\n      keras_cv.layers.MixUp(\\n          alpha=0.5,\\n      ),\\n      keras_cv.layers.CutMix(\\n          alpha=0.5\\n      ),\\n    ]\\n  )\\n\\n  inputs = {\"images\": images, \"labels\": labels}\\n  output = augmenter(inputs)\\n  return output[\"images\"], output[\"labels\"]'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":13}],"source":["# Function to get a set of layers for augmentation 2\n","\"\"\"def augment(images, labels):\n","  augmenter = keras_cv.layers.Augmenter(\n","    layers = [\n","      keras_cv.layers.RandomFlip(\n","          mode=\"horizontal_and_vertical\"\n","      ),\n","      keras_cv.layers.RandomRotation(\n","          factor=0.2,\n","          fill_mode='nearest'\n","      ),\n","      keras_cv.layers.MixUp(\n","          alpha=0.5,\n","      ),\n","      keras_cv.layers.CutMix(\n","          alpha=0.5\n","      ),\n","    ]\n","  )\n","\n","  inputs = {\"images\": images, \"labels\": labels}\n","  output = augmenter(inputs)\n","  return output[\"images\"], output[\"labels\"]\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1732437446306,"user":{"displayName":"Alessandro","userId":"13573195732524414409"},"user_tz":-60},"id":"uGFIStLM44-0","colab":{"base_uri":"https://localhost:8080/","height":70},"outputId":"54383b0e-ac44-42ab-e684-4b5f7cc78ce3"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'def sample_random_images(dataset, sample_size=5):\\n    random_samples = dataset.shuffle(buffer_size=1000).take(sample_size)\\n    images = []\\n    labels = []\\n    for image, label in random_samples:\\n        images.append(image.numpy())\\n        labels.append(label.numpy())\\n    return tf.convert_to_tensor(images), tf.convert_to_tensor(labels)\\n\\n# Convert the previously constructed data into tf.data.Dataset\\nx_train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":14}],"source":["# This function returns random (image, label) pairs\n","\"\"\"def sample_random_images(dataset, sample_size=5):\n","    random_samples = dataset.shuffle(buffer_size=1000).take(sample_size)\n","    images = []\n","    labels = []\n","    for image, label in random_samples:\n","        images.append(image.numpy())\n","        labels.append(label.numpy())\n","    return tf.convert_to_tensor(images), tf.convert_to_tensor(labels)\n","\n","# Convert the previously constructed data into tf.data.Dataset\n","x_train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":70},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1732437446306,"user":{"displayName":"Alessandro","userId":"13573195732524414409"},"user_tz":-60},"id":"nts2hQk944-0","outputId":"daa12bde-ff01-44a7-ebb9-b4c6140c7be5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'# We take 4000 random images and augment them\\nsample_size = 4000\\nrandom_x, random_y = sample_random_images(x_train_dataset, sample_size)\\nprint(f\"{len(random_x)} {len(random_y)}\")\\naug_images, aug_labels = augment(random_x, random_y)\\n\\n# We concatenate these 4000 new augmented pictures to the originale dataset\\nx_train = tf.concat([x_train, aug_images], axis=0)\\ny_train = tf.concat([y_train, aug_labels], axis=0)\\n\\nprint(x_train.shape)\\nprint(y_train.shape)\\n\\ndel random_x\\ndel random_y'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":15}],"source":["\"\"\"# We take 4000 random images and augment them\n","sample_size = 4000\n","random_x, random_y = sample_random_images(x_train_dataset, sample_size)\n","print(f\"{len(random_x)} {len(random_y)}\")\n","aug_images, aug_labels = augment(random_x, random_y)\n","\n","# We concatenate these 4000 new augmented pictures to the originale dataset\n","x_train = tf.concat([x_train, aug_images], axis=0)\n","y_train = tf.concat([y_train, aug_labels], axis=0)\n","\n","print(x_train.shape)\n","print(y_train.shape)\n","\n","del random_x\n","del random_y\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1732437446306,"user":{"displayName":"Alessandro","userId":"13573195732524414409"},"user_tz":-60},"id":"290GYoe1R7Y-","colab":{"base_uri":"https://localhost:8080/","height":104},"outputId":"5f80a51a-90bf-457a-acc8-35db2c281cbb"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'def apply_augmentation(image, is_randaugment):\\n    if is_randaugment:\\n        return apply_randaugment(image)\\n    else:\\n        return apply_augmix(image)\\n\\ndef apply_augmix(image):\\n    return augmix(image)\\n\\ndef apply_randaugment(image):\\n    return randaugmenter(image)\\n\\nrandaugmenter = tf.keras.Sequential(\\n    [\\n        keras_cv.layers.RandAugment([0, 255], 3, 0.5), # it was 0.4 instead of 0.5\\n    ]\\n)\\n\\naugmix = tf.keras.Sequential(\\n    [\\n        keras_cv.layers.AugMix([0, 255], 0.4), # no number was set for severity, so it was 0.3\\n    ]\\n)\\n\\nbatch_size = 256\\nhalf_size = len(x_train) // 2\\n\\n# We apply the RandAugment augmentation to the first half of the dataset\\ndataset_randaugment = tf.data.Dataset.from_tensor_slices(x_train[:half_size])\\ndataset_randaugment = dataset_randaugment.map(lambda x: apply_augmentation(x, is_randaugment=True), num_parallel_calls=tf.data.AUTOTUNE)\\n\\n# We apply the AugMix augmentation to the second half of the dataset\\ndataset_augmix = tf.data.Dataset.from_tensor_slices(x_train[half_size:])\\ndataset_augmix = dataset_augmix.map(lambda x: apply_augmentation(x, is_randaugment=False), num_parallel_calls=tf.data.AUTOTUNE)\\n\\ndataset = dataset_randaugment.concatenate(dataset_augmix)\\ndataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\\n\\nx_train = tf.concat([batch for batch in dataset], axis=0)\\n\\ndel x_train_dataset'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":16}],"source":["\"\"\"def apply_augmentation(image, is_randaugment):\n","    if is_randaugment:\n","        return apply_randaugment(image)\n","    else:\n","        return apply_augmix(image)\n","\n","def apply_augmix(image):\n","    return augmix(image)\n","\n","def apply_randaugment(image):\n","    return randaugmenter(image)\n","\n","randaugmenter = tf.keras.Sequential(\n","    [\n","        keras_cv.layers.RandAugment([0, 255], 3, 0.5), # it was 0.4 instead of 0.5\n","    ]\n",")\n","\n","augmix = tf.keras.Sequential(\n","    [\n","        keras_cv.layers.AugMix([0, 255], 0.4), # no number was set for severity, so it was 0.3\n","    ]\n",")\n","\n","batch_size = 256\n","half_size = len(x_train) // 2\n","\n","# We apply the RandAugment augmentation to the first half of the dataset\n","dataset_randaugment = tf.data.Dataset.from_tensor_slices(x_train[:half_size])\n","dataset_randaugment = dataset_randaugment.map(lambda x: apply_augmentation(x, is_randaugment=True), num_parallel_calls=tf.data.AUTOTUNE)\n","\n","# We apply the AugMix augmentation to the second half of the dataset\n","dataset_augmix = tf.data.Dataset.from_tensor_slices(x_train[half_size:])\n","dataset_augmix = dataset_augmix.map(lambda x: apply_augmentation(x, is_randaugment=False), num_parallel_calls=tf.data.AUTOTUNE)\n","\n","dataset = dataset_randaugment.concatenate(dataset_augmix)\n","dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n","\n","x_train = tf.concat([batch for batch in dataset], axis=0)\n","\n","del x_train_dataset\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":104},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1732437446306,"user":{"displayName":"Alessandro","userId":"13573195732524414409"},"user_tz":-60},"id":"LolaIQ1E44-0","outputId":"e110574c-8367-4676-bcb0-5e82d6309ce5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'# We define a new set of augmentations 3\\naugmenter = keras_cv.layers.Augmenter(\\n  layers = [\\n    keras_cv.layers.RandAugment([0, 255], 3, 0.5),\\n    keras_cv.layers.AugMix([0, 255], 0.4),\\n\\n    keras_cv.layers.RandomCutout(0.075, 0.075, fill_mode=\"gaussian_noise\"),\\n    keras_cv.layers.RandomCutout(0.075, 0.075, fill_mode=\"gaussian_noise\"),\\n    keras_cv.layers.RandomCutout(0.075, 0.075, fill_mode=\"gaussian_noise\"),\\n    keras_cv.layers.RandomCutout(0.075, 0.075, fill_mode=\"gaussian_noise\"),\\n    keras_cv.layers.RandomCutout(0.075, 0.075, fill_mode=\"gaussian_noise\"),\\n  ]\\n)\\n\\n# And again we apply this new augmenter to other 7000 images\\nsample_size = 7000\\nrandom_x, random_y = sample_random_images(dataset, sample_size)\\n#del dataset\\nrandom_y = tf.cast(random_y, dtype=tf.float32)\\naug_images = augmenter(random_x)\\n\\nx_train = tf.concat([x_train, aug_images], axis=0)\\ny_train = tf.concat([y_train, random_y], axis=0)\\n\\nx_train = x_train.numpy()\\ny_train = y_train.numpy()\\n\\n######### print(x_train.shape)\\n######### print(aug_images.shape)\\n######### print(random_y.shape)\\n\\nx_train=tf.cast(x_train, dtype=tf.float32)\\n\\nnp.savez_compressed(\\'dataset_augmented_default.npz\\', images=x_train, labels=y_train)\\n\\nprint(x_train.shape)'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":17}],"source":["\"\"\"# We define a new set of augmentations 3\n","augmenter = keras_cv.layers.Augmenter(\n","  layers = [\n","    keras_cv.layers.RandAugment([0, 255], 3, 0.5),\n","    keras_cv.layers.AugMix([0, 255], 0.4),\n","\n","    keras_cv.layers.RandomCutout(0.075, 0.075, fill_mode=\"gaussian_noise\"),\n","    keras_cv.layers.RandomCutout(0.075, 0.075, fill_mode=\"gaussian_noise\"),\n","    keras_cv.layers.RandomCutout(0.075, 0.075, fill_mode=\"gaussian_noise\"),\n","    keras_cv.layers.RandomCutout(0.075, 0.075, fill_mode=\"gaussian_noise\"),\n","    keras_cv.layers.RandomCutout(0.075, 0.075, fill_mode=\"gaussian_noise\"),\n","  ]\n",")\n","\n","# And again we apply this new augmenter to other 7000 images\n","sample_size = 7000\n","random_x, random_y = sample_random_images(dataset, sample_size)\n","#del dataset\n","random_y = tf.cast(random_y, dtype=tf.float32)\n","aug_images = augmenter(random_x)\n","\n","x_train = tf.concat([x_train, aug_images], axis=0)\n","y_train = tf.concat([y_train, random_y], axis=0)\n","\n","x_train = x_train.numpy()\n","y_train = y_train.numpy()\n","\n","######### print(x_train.shape)\n","######### print(aug_images.shape)\n","######### print(random_y.shape)\n","\n","x_train=tf.cast(x_train, dtype=tf.float32)\n","\n","np.savez_compressed('dataset_augmented_default.npz', images=x_train, labels=y_train)\n","\n","print(x_train.shape)\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1732437446306,"user":{"displayName":"Alessandro","userId":"13573195732524414409"},"user_tz":-60},"id":"J2Q6-Qdm44-2","outputId":"7387b880-6e7f-44ba-99c4-7af54b1a0ca4"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"# We show an image with the latest augmentation (3)\\nplt.imshow(x_train[-4] / 255.0)\\nprint('Class', aug_labels[1])\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":18}],"source":["import matplotlib.pyplot as plt\n","\n","\"\"\"# We show an image with the latest augmentation (3)\n","plt.imshow(x_train[-4] / 255.0)\n","print('Class', aug_labels[1])\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rZiX8emjBZ3U"},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","import keras_cv\n","from tensorflow import keras as tfk\n","from tensorflow.keras import layers, models, applications\n","from tensorflow.keras.callbacks import LambdaCallback\n","import random\n","import keras\n","from keras.saving import register_keras_serializable\n","from sklearn.utils.class_weight import compute_class_weight\n","\n","def spatial_attention(input_tensor):\n","    \"\"\"\n","    Spatial Attention Block.\n","\n","    Args:\n","        input_tensor (tf.Tensor): Input feature map, shape (batch, height, width, channels).\n","\n","    Returns:\n","        tf.Tensor: Output tensor after applying spatial attention.\n","    \"\"\"\n","    # Media e massimo pooling lungo l'asse dei canali come livelli Keras\n","    avg_pool = tfk.layers.Lambda(lambda x: tf.reduce_mean(x, axis=-1, keepdims=True))(input_tensor)\n","    max_pool = tfk.layers.Lambda(lambda x: tf.reduce_max(x, axis=-1, keepdims=True))(input_tensor)\n","\n","    # Concatenazione delle due mappe di attenzione\n","    concat = tfk.layers.Concatenate(axis=-1)([avg_pool, max_pool])  # Shape: (batch, height, width, 2)\n","\n","    # Convoluzione per generare la mappa di attenzione spaziale\n","    attention = tfk.layers.Conv2D(1, kernel_size=7, padding='same', activation='sigmoid')(concat)  # Shape: (batch, height, width, 1)\n","\n","    # Scala l'input con la mappa di attenzione\n","    output = tfk.layers.Multiply()([input_tensor, attention])  # Shape: (batch, height, width, channels)\n","\n","    return output"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OM8fYnpvNza0"},"outputs":[],"source":["# These were initially inside the get augmetnation layer\n","\n","\"\"\"\"\"\"\n","\n","class MyModel:\n","    def __init__(self):\n","        \"\"\"\n","        Inizializza lo stato interno del modello pretrained.\n","        \"\"\"\n","        self.strategy = tf.distribute.MirroredStrategy()\n","        self.neural_network = self.create_model()\n","\n","    def get_augmentation_layer(self):\n","        return tf.keras.Sequential([\n","\n","            # Random rotation\n","            keras.layers.RandomRotation(0.5, fill_mode='reflect'),\n","\n","            # Random zoom in height\n","            keras.layers.RandomZoom(height_factor=(-0.2, 0.7), fill_mode='nearest'),\n","\n","            # Other types of augmentations\n","            keras.layers.RandomZoom(height_factor=(0.0, 0.0), width_factor=(-0.3, 0.3), fill_mode='nearest'),\n","            keras.layers.RandomFlip(mode=\"horizontal\"),\n","            keras.layers.RandomFlip(mode=\"vertical\"),\n","            keras.layers.RandomTranslation(height_factor=(-0.2, 0.2), width_factor=(-0.2, 0.2)),\n","\n","            keras.layers.RandomBrightness(0.3),\n","            #keras_cv.layers.RandomHue(0.3, [0,255]),\n","            keras_cv.layers.RandomContrast([0, 255], 0.3),\n","            keras_cv.layers.RandomGaussianBlur(2, 2),\n","            #keras_cv.layers.RandomCutout(0.3, 0.3,\"gaussian_noise\"),\n","\n","            # Adding Gaussian noise\n","            keras.layers.GaussianNoise(0.07)\n","\n","        ])\n","\n","\n","    def create_model(self):\n","        \"\"\"\n","        Crea e restituisce un modello\n","        \"\"\"\n","        # Definisci i layer di data augmentation\n","        data_augmentation = self.get_augmentation_layer()\n","\n","        with self.strategy.scope():\n","\n","            # Utilizza una rete pre-addestrata\n","            #model_pretrained = tfk.applications.ConvNeXtBase(\n","            model_pretrained = tfk.applications.ConvNeXtXLarge(\n","                input_shape=(96, 96, 3),\n","                include_top=False,\n","                weights='imagenet',\n","                pooling=None\n","            )\n","            #self.model_name_pretrained = 'convnext_base'\n","            self.model_name_pretrained = 'convnext_xlarge'\n","\n","            print(\"number of layers:\")\n","            print(len(model_pretrained.layers))\n","\n","            # Costruisci il modello\n","            inputs = tfk.Input(shape=(96, 96, 3), name='input_layer')\n","            x = data_augmentation(inputs)\n","            x = model_pretrained(x)\n","\n","            # Batch Normalization dopo il modello pre-addestrato\n","            x = tfk.layers.BatchNormalization()(x)\n","\n","            # Squeeze-and-Excitation (SE Block)\n","            se = tfk.layers.GlobalAveragePooling2D()(x)  # Riduce a (batch_size, channels)\n","            se = tfk.layers.Dense(se.shape[-1] // 16, activation='relu')(se)  # Compress\n","            se = tfk.layers.Dense(se.shape[-1] * 16, activation='sigmoid')(se)  # Expand\n","            x = tfk.layers.Multiply()([x, tfk.layers.Reshape((1, 1, -1))(se)])  # Scala i canali\n","\n","            # Global Pooling (per ridurre la dimensionalit√†)\n","            x = tfk.layers.GlobalAveragePooling2D()(x)\n","\n","            # Livelli Fully Connected con Batch Normalization e Leaky ReLU\n","            x = tfk.layers.Dense(512)(x)\n","            x = tfk.layers.BatchNormalization()(x)\n","            x = tfk.layers.LeakyReLU(alpha=0.1)(x)\n","            x = tfk.layers.Dropout(0.3)(x)\n","\n","            x = tfk.layers.Dense(256)(x)\n","            x = tfk.layers.BatchNormalization()(x)\n","            x = tfk.layers.LeakyReLU(alpha=0.1)(x)\n","            x = tfk.layers.Dropout(0.3)(x)\n","\n","            outputs = tfk.layers.Dense(8, activation='softmax', name='output_layer')(x)\n","\n","            model = tfk.Model(inputs=inputs, outputs=outputs, name='model')\n","\n","            return model\n","\n","    def train_transfer_learning(self, X_train, y_train, X_test, y_test, epochs=10, batch_size=32):\n","        \"\"\"\n","        Pre-addestra il modello con i layer congelati.\n","        \"\"\"\n","\n","        with self.strategy.scope():  # Ensure training happens inside strategy scope\n","\n","            self.neural_network.get_layer(self.model_name_pretrained).trainable = False\n","\n","            # Sblocca i layer convoluzionali dal layer `fine_tune_from` in poi\n","            for i, layer in enumerate(self.neural_network.get_layer(self.model_name_pretrained).layers):\n","                layer.trainable = False\n","\n","            # Ricompila il modello (necessario dopo aver modificato i layer trainabili)\n","            self.neural_network.compile(\n","                loss=tfk.losses.CategoricalCrossentropy(),\n","                optimizer=tfk.optimizers.Lion(learning_rate=1e-3),\n","                metrics=['accuracy']\n","            )\n","\n","\n","            # Callback\n","            save_every_5 = LambdaCallback(\n","                on_epoch_end=lambda epoch, logs:\n","                self.neural_network.save(f'model_epoch_{epoch + 1}.keras') if (epoch + 1) % 5 == 0 else None\n","            )\n","            early_stopping = tfk.callbacks.EarlyStopping(\n","                monitor='val_accuracy',\n","                mode='max',\n","                patience=8,\n","                restore_best_weights=True\n","            )\n","\n","            # Riaddestra il modello\n","            history = self.neural_network.fit(\n","                X_train,\n","                y_train,\n","                batch_size=batch_size,\n","                epochs=epochs,\n","                shuffle=True,\n","                validation_data=(X_test, y_test),\n","                callbacks=[save_every_5, early_stopping]\n","            )\n","\n","    def train_fine_tuning(self, X_train, y_train, X_test, y_test, epochs=10, batch_size=32, fine_tune_from=50):\n","        \"\"\"\n","        Sblocca i layer selezionati e riaddestra il modello.\n","        \"\"\"\n","\n","        with self.strategy.scope():  # Ensure training happens inside strategy scope\n","\n","            self.neural_network.get_layer(self.model_name_pretrained).trainable = True\n","\n","            # Sblocca i layer convoluzionali dal layer `fine_tune_from` in poi\n","            for i, layer in enumerate(self.neural_network.get_layer(self.model_name_pretrained).layers):\n","                layer.trainable = False\n","                if i > fine_tune_from:\n","                  if isinstance(layer, tf.keras.layers.Conv2D) or isinstance(layer, tf.keras.layers.DepthwiseConv2D):\n","                    print(True)\n","                    layer.trainable = True\n","\n","\n","            # Ricompila il modello con un learning rate pi√π basso\n","            self.neural_network.compile(\n","                loss=tfk.losses.CategoricalCrossentropy(),\n","                #optimizer=tfk.optimizers.Lion(learning_rate=1e-4),\n","                optimizer=tfk.optimizers.Lion(learning_rate=1e-3),\n","                metrics=['accuracy']\n","            )\n","\n","            # Callback\n","            save_every_5 = LambdaCallback(\n","                on_epoch_end=lambda epoch, logs:\n","                self.neural_network.save(f'model_epoch_{epoch + 1}.keras') if (epoch + 1) % 5 == 0 else None\n","            )\n","            early_stopping = tfk.callbacks.EarlyStopping(\n","                monitor='val_accuracy',\n","                mode='max',\n","                patience=8,\n","                restore_best_weights=True\n","            )\n","\n","\n","            # Riaddestra il modello\n","            history = self.neural_network.fit(\n","                X_train,\n","                y_train,\n","                batch_size=batch_size,\n","                epochs=epochs,\n","                shuffle=True,\n","                validation_data=(X_test, y_test),\n","                callbacks=[save_every_5, early_stopping]\n","            )\n","\n","    def test(self, X_test, y_test):\n","        \"\"\"\n","        Valuta il modello sui dati di test X_test e le etichette y_test.\n","        \"\"\"\n","        test_loss, test_acc = self.neural_network.evaluate(X_test, y_test)\n","        print(f'Test accuracy: {test_acc}')\n","\n","    def load(self, path):\n","\n","        # Re-compile the model inside the strategy scope\n","        with self.strategy.scope():\n","            self.neural_network = tfk.models.load_model(path)\n","            self.neural_network.compile(\n","                loss=tfk.losses.CategoricalCrossentropy(),\n","                optimizer=tfk.optimizers.Lion(),  # Create optimizer inside the scope\n","                metrics=['accuracy']\n","            )\n","\n","    def save(self):\n","        \"\"\"\n","        Salva il modello senza i layer di data augmentation.\n","        \"\"\"\n","        self.neural_network.save('/gdrive/MyDrive/[2024-2025] AN2DL/Homework 1/Base_3/weights.keras')\n","\n","    def predict(self, X):\n","        \"\"\"\n","        Predice le etichette corrispondenti all'input X.\n","        \"\"\"\n","        preds = self.neural_network.predict(X)\n","        preds = np.argmax(preds, axis=1)\n","        return preds"]},{"cell_type":"markdown","metadata":{"id":"FSliIxBvbs2Q"},"source":["## üõ†Ô∏è Train and Save the Model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":72721,"status":"ok","timestamp":1732437519268,"user":{"displayName":"Alessandro","userId":"13573195732524414409"},"user_tz":-60},"id":"hHk2sh_qGXLw","outputId":"9eca1ebb-d9fb-4b6d-ca61-b08e04c7a62c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/convnext/convnext_xlarge_notop.h5\n","\u001b[1m1393257616/1393257616\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 0us/step\n","number of layers:\n","259\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n","  warnings.warn(\n"]}],"source":["model = MyModel()\n","\n","# Load the saved model\n","model_path = \"model_epoch_15.keras\"\n","with model.strategy.scope():\n","    loaded_network = tf.keras.models.load_model(model_path)\n","model.neural_network = loaded_network"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":70},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1732437519268,"user":{"displayName":"Alessandro","userId":"13573195732524414409"},"user_tz":-60},"id":"_IqqnFcq8KnX","outputId":"f6a6c2a7-c768-4e5c-ba4b-d67d131f80f5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'data_augmentation = model.get_augmentation_layer()\\n\\n# We apply the first set of augmentations to a random picture\\nrotated_image = data_augmentation(x_train[0])\\nprint(y_train[6001])\\n\\n# Show the original image as well as the rotated one\\nplt.figure(figsize=(10, 5))\\n\\n# Show the rotated image\\nplt.subplot(1, 2, 1)\\nplt.imshow(x_train[0] / 255.0)\\nplt.title(\"Immagine Ruotata\")\\nplt.axis(\\'off\\')\\n\\n\\'\\'\\'\\n# Mostra l\\'immagine ruotata\\nplt.subplot(1, 2, 2)\\nplt.imshow(rotated_image / 255.0)\\nplt.title(\"Immagine Ruotata\")\\nplt.axis(\\'off\\')\\'\\'\\'\\n\\nplt.show()'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":22}],"source":["import matplotlib.pyplot as plt\n","import keras_cv\n","\n","\"\"\"data_augmentation = model.get_augmentation_layer()\n","\n","# We apply the first set of augmentations to a random picture\n","rotated_image = data_augmentation(x_train[0])\n","print(y_train[6001])\n","\n","# Show the original image as well as the rotated one\n","plt.figure(figsize=(10, 5))\n","\n","# Show the rotated image\n","plt.subplot(1, 2, 1)\n","plt.imshow(x_train[0] / 255.0)\n","plt.title(\"Immagine Ruotata\")\n","plt.axis('off')\n","\n","'''\n","# Mostra l'immagine ruotata\n","plt.subplot(1, 2, 2)\n","plt.imshow(rotated_image / 255.0)\n","plt.title(\"Immagine Ruotata\")\n","plt.axis('off')'''\n","\n","plt.show()\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wJvoNKpU44-5"},"outputs":[],"source":["#model.load('/kaggle/working/model_epoch_10.keras')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dcVWLb-jGRd5"},"outputs":[],"source":["#x_test_augmented = model.get_augmentation_layer()(x_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1732437519268,"user":{"displayName":"Alessandro","userId":"13573195732524414409"},"user_tz":-60},"id":"somuYQZT44-5","outputId":"dfabc400-3269-4abc-82ff-a921218935a9"},"outputs":[{"output_type":"stream","name":"stdout","text":["float32\n"]}],"source":["print(x_train.dtype)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NfyHkIEQ44-6"},"outputs":[],"source":["#model.train_transfer_learning(x_train, y_train, x_test, y_test, 50, 512)\n","#model.train_transfer_learning(x_train, y_train, x_test, y_test, 1, 512)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TSm6IFUCP5Vh"},"outputs":[],"source":["#model.neural_network.save('weights_xl_1.keras')"]},{"cell_type":"code","source":["print(f\"Len: {len(x_train)}\\n Shape: {x_train.shape}\\n\")\n","print(f\"Len: {len(y_train)}\\n Shape: {y_train.shape}\\n\")\n","print(f\"Len: {len(x_test)}\\n Shape: {x_test.shape}\\n\")\n","print(f\"Len: {len(y_test)}\\n Shape: {y_test.shape}\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aYC5g8T9S2Op","executionInfo":{"status":"ok","timestamp":1732437519268,"user_tz":-60,"elapsed":4,"user":{"displayName":"Alessandro","userId":"13573195732524414409"}},"outputId":"4da2b508-6328-41a2-ef65-f54cec27d7a2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Len: 20776\n"," Shape: (20776, 96, 96, 3)\n","\n","Len: 20776\n"," Shape: (20776, 8)\n","\n","Len: 11943\n"," Shape: (11943, 96, 96, 3)\n","\n","Len: 11943\n"," Shape: (11943, 8)\n","\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"x5CJLeaw44-6","executionInfo":{"status":"error","timestamp":1732482094804,"user_tz":-60,"elapsed":44575540,"user":{"displayName":"Alessandro","userId":"13573195732524414409"}},"outputId":"6ce1ebf6-a841-4333-db91-c0e0d3166318"},"outputs":[{"output_type":"stream","name":"stdout","text":["True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","Epoch 1/50\n","\u001b[1m163/163\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2281s\u001b[0m 14s/step - accuracy: 0.8302 - loss: 0.5675 - val_accuracy: 0.9637 - val_loss: 0.1075\n","Epoch 2/50\n","\u001b[1m163/163\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2236s\u001b[0m 14s/step - accuracy: 0.8290 - loss: 0.5741 - val_accuracy: 0.9687 - val_loss: 0.0897\n","Epoch 3/50\n","\u001b[1m163/163\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2259s\u001b[0m 14s/step - accuracy: 0.8294 - loss: 0.5703 - val_accuracy: 0.9664 - val_loss: 0.0970\n","Epoch 4/50\n","\u001b[1m163/163\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2231s\u001b[0m 14s/step - accuracy: 0.8224 - loss: 0.5857 - val_accuracy: 0.9673 - val_loss: 0.0969\n","Epoch 5/50\n","\u001b[1m163/163\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2491s\u001b[0m 15s/step - accuracy: 0.8295 - loss: 0.5644 - val_accuracy: 0.9627 - val_loss: 0.1073\n","Epoch 6/50\n","\u001b[1m163/163\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2230s\u001b[0m 14s/step - accuracy: 0.8328 - loss: 0.5712 - val_accuracy: 0.9602 - val_loss: 0.1207\n","Epoch 7/50\n","\u001b[1m163/163\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2233s\u001b[0m 14s/step - accuracy: 0.8348 - loss: 0.5601 - val_accuracy: 0.9637 - val_loss: 0.1059\n","Epoch 8/50\n","\u001b[1m163/163\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2236s\u001b[0m 14s/step - accuracy: 0.8402 - loss: 0.5558 - val_accuracy: 0.9619 - val_loss: 0.1109\n","Epoch 9/50\n","\u001b[1m163/163\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2229s\u001b[0m 14s/step - accuracy: 0.8350 - loss: 0.5526 - val_accuracy: 0.9653 - val_loss: 0.1026\n","Epoch 10/50\n","\u001b[1m163/163\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2442s\u001b[0m 15s/step - accuracy: 0.8378 - loss: 0.5500 - val_accuracy: 0.9691 - val_loss: 0.0870\n","Epoch 11/50\n","\u001b[1m163/163\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2234s\u001b[0m 14s/step - accuracy: 0.8412 - loss: 0.5521 - val_accuracy: 0.9626 - val_loss: 0.1048\n","Epoch 12/50\n","\u001b[1m163/163\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2258s\u001b[0m 14s/step - accuracy: 0.8414 - loss: 0.5510 - val_accuracy: 0.9704 - val_loss: 0.0855\n","Epoch 13/50\n","\u001b[1m163/163\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2231s\u001b[0m 14s/step - accuracy: 0.8385 - loss: 0.5472 - val_accuracy: 0.9597 - val_loss: 0.1140\n","Epoch 14/50\n","\u001b[1m163/163\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2258s\u001b[0m 14s/step - accuracy: 0.8397 - loss: 0.5479 - val_accuracy: 0.9622 - val_loss: 0.1081\n","Epoch 15/50\n","\u001b[1m163/163\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2425s\u001b[0m 15s/step - accuracy: 0.8478 - loss: 0.5377 - val_accuracy: 0.9661 - val_loss: 0.1030\n","Epoch 16/50\n","\u001b[1m163/163\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2255s\u001b[0m 14s/step - accuracy: 0.8474 - loss: 0.5309 - val_accuracy: 0.9703 - val_loss: 0.0863\n","Epoch 17/50\n","\u001b[1m163/163\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2237s\u001b[0m 14s/step - accuracy: 0.8416 - loss: 0.5356 - val_accuracy: 0.9729 - val_loss: 0.0770\n","Epoch 18/50\n","\u001b[1m163/163\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2231s\u001b[0m 14s/step - accuracy: 0.8491 - loss: 0.5232 - val_accuracy: 0.9730 - val_loss: 0.0794\n","Epoch 19/50\n","\u001b[1m163/163\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2233s\u001b[0m 14s/step - accuracy: 0.8440 - loss: 0.5310 - val_accuracy: 0.9711 - val_loss: 0.0851\n","Epoch 20/50\n","\u001b[1m132/163\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[1m5:10\u001b[0m 10s/step - accuracy: 0.8469 - loss: 0.5264"]},{"output_type":"stream","name":"stderr","text":["ERROR:root:Internal Python error in the inspect module.\n","Below is the traceback from this internal error.\n","\n"]},{"output_type":"stream","name":"stdout","text":["Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"<ipython-input-29-4a6438a9a9f0>\", line 2, in <cell line: 2>\n","    model.train_fine_tuning(x_train, y_train, x_test, y_test, 50, 128, 150)\n","  File \"<ipython-input-20-22a9cb61a0d8>\", line 181, in train_fine_tuning\n","    history = self.neural_network.fit(\n","  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n","    return fn(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 318, in fit\n","    logs = self.train_function(iterator)\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n","    return fn(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 833, in __call__\n","    result = self._call(*args, **kwds)\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 878, in _call\n","    results = tracing_compilation.call_function(\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\", line 139, in call_function\n","    return function._call_flat(  # pylint: disable=protected-access\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\", line 1322, in _call_flat\n","    return self._inference_function.call_preflattened(args)\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 216, in call_preflattened\n","    flat_outputs = self.call_flat(*args)\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 251, in call_flat\n","    outputs = self._bound_context.call_function(\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\", line 1552, in call_function\n","    outputs = execute.execute(\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\", line 53, in quick_execute\n","    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n","KeyboardInterrupt\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n","    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n","    return f(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n","    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n","  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n","    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n","  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n","    filename = getsourcefile(frame) or getfile(frame)\n","  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n","    module = getmodule(object, filename)\n","  File \"/usr/lib/python3.10/inspect.py\", line 875, in getmodule\n","    f = getabsfile(module)\n","  File \"/usr/lib/python3.10/inspect.py\", line 844, in getabsfile\n","    _filename = getsourcefile(object) or getfile(object)\n","  File \"/usr/lib/python3.10/inspect.py\", line 826, in getsourcefile\n","    if os.path.exists(filename):\n","  File \"/usr/lib/python3.10/genericpath.py\", line 19, in exists\n","    os.stat(path)\n","KeyboardInterrupt\n"]},{"output_type":"error","ename":"TypeError","evalue":"object of type 'NoneType' has no len()","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n","\u001b[0;32m<ipython-input-29-4a6438a9a9f0>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#model.train_fine_tuning(x_train, y_train, x_test, y_test, 50, 512, 150)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_fine_tuning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m150\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-20-22a9cb61a0d8>\u001b[0m in \u001b[0;36mtrain_fine_tuning\u001b[0;34m(self, X_train, y_train, X_test, y_test, epochs, batch_size, fine_tune_from)\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;31m# Riaddestra il modello\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             history = self.neural_network.fit(\n\u001b[0m\u001b[1;32m    182\u001b[0m                 \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    317\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pythonify_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1552\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1553\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: ","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2098\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2099\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2099\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2101\u001b[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[1;32m   2102\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[1;32m   2103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"]}],"source":["#model.train_fine_tuning(x_train, y_train, x_test, y_test, 50, 512, 150)\n","model.train_fine_tuning(x_train, y_train, x_test, y_test, 50, 128, 150)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eh8CgV3b44-6"},"outputs":[],"source":["model.neural_network.save('weights_xl_2.keras')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-KpPjlAs44-7"},"outputs":[],"source":["\"\"\"model2 = model.neural_network\n","model2.compile(\n","  loss=tfk.losses.CategoricalCrossentropy(),\n","  optimizer=tfk.optimizers.Lion(learning_rate=1e-4),\n","  metrics=['accuracy']\n",")\n","\n","model2.save('weights_squeeze.keras')\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BPTK4moBCGrc"},"outputs":[],"source":["# Carica il dataset\n","\"\"\"data_original = np.load('training_set.npz')\n","x_test = data_original['images']\n","y_test = data_original['labels']\"\"\"\n","\n","x_test = tf.cast(x_train, dtype=tf.float32)  # Convert to float32 if required\n","#y_test = tf.keras.utils.to_categorical(y_train, num_classes=8)\n","\n","print(f\"{y_train[0]} end\")\n","print(f\"{y_test[0]}\")\n","\n","\"\"\"# Load the model\n","model = tf.keras.models.load_model('weights_xl_2.keras')\n","\n","# Test the model on some data\n","# Get predictions\n","predictions = model.predict(x_train)\n","\n","# Evaluate the model\n","loss, accuracy = model.evaluate(x_train, y_train)\n","print(f\"Loss: {loss}, Accuracy: {accuracy}\")\n","\n","# Example: print the predicted class for the first sample\n","predicted_class = tf.argmax(predictions[0]).numpy()\n","print(f\"Predicted class for the first sample: {predicted_class}\")\"\"\"\n","\n","\n","model.test(x_test, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Syb4AHsnicdk"},"outputs":[],"source":["preds = model.predict(x_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_ystjv8Wun5B"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n","y_true = np.argmax(y_train, axis=1)\n","y_pred = preds\n","# Genera la confusion matrix\n","cm = confusion_matrix(y_true, y_pred)\n","# Visualizza la confusion matrix con le etichette\n","disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n","disp.plot(cmap=plt.cm.Blues)\n","# Usa una mappa di colori blu\n","plt.title(\"Confusion Matrix\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4qMqkETBBvj0"},"outputs":[],"source":["#model.neural_network.save('/gdrive/MyDrive/weights.keras')"]},{"cell_type":"markdown","metadata":{"id":"RNp6pUZuddqC"},"source":["## üìä Prepare Your SubmissionTo prepare your submission, create a `.zip` file that includes all the necessary code to run your model. It **must** include a `model.py` file with the following class:```python# file: model.pyclass Model:    def __init__(self):        \"\"\"Initialize the internal state of the model.\"\"\"    def predict(self, X):        \"\"\"Return a numpy array with the labels corresponding to the input X.\"\"\"```The next cell shows an example implementation of the `model.py` file, which includes loading model weights from the `weights.keras` file and conducting predictions on provided input data. The `.zip` file is created and downloaded in the last notebook cell.‚ùó Feel free to modify the method implementations to better fit your specific requirements, but please ensure that the class name and method interfaces remain unchanged."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RKT4h-9xYwiT"},"outputs":[],"source":["%%writefile '/gdrive/My Drive/[2024-2025] AN2DL/Homework 1/Base_3/model.py'\n","\n","import numpy as np\n","\n","import tensorflow as tf\n","from tensorflow import keras as tfk\n","from tensorflow.keras import layers as tfkl\n","\n","class Model:\n","  def __init__(self):        # Carica il modello senza compilazione\n","    self.neural_network = tfk.models.load_model('weights.keras')\n","\n","  def test(self, X_test, y_test):\n","    test_loss, test_acc = self.neural_network.evaluate(X_test, y_test)\n","    print(f'Test accuracy: {test_acc}')\n","\n","  def predict(self, X):\n","    preds = self.neural_network.predict(X)\n","    if len(preds.shape) == 2:\n","      preds = np.argmax(preds, axis=1)\n","      return preds"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T9qoFhPzfa6D"},"outputs":[],"source":["#model3 = Model2()\n","#model3.test(X_test2, y_test2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BHm_n-9kSFpv"},"outputs":[],"source":["from datetime import datetime\n","\n","#filename1 = f'submission_{datetime.now().strftime(\"%y%m%d_%H%M%S\")}_NOFN.zip'\n","filename2 = f'submission_{datetime.now().strftime(\"%y%m%d_%H%M%S\")}_FN.zip'\n","\n","# Add files to the zip command if needed\n","#!zip {filename1} model.py weights_xl_1.keras\n","!zip {filename2} model.py weights_xl_2.keras\n","\n","from google.colab import files\n","#files.download(filename1)\n","files.download(filename2)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":6092801,"sourceId":9915012,"sourceType":"datasetVersion"},{"datasetId":6104425,"sourceId":9930890,"sourceType":"datasetVersion"},{"datasetId":6115708,"sourceId":9945705,"sourceType":"datasetVersion"}],"dockerImageVersionId":30787,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":0}