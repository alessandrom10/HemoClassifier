{"cells":[{"cell_type":"markdown","metadata":{"id":"nuwVgG3Vbbka"},"source":["## **Introduction**\n","In this notebook, we will build and train a neural network for classifying blood cells using ResNet, a deep residual network architecture.\n","\n","This project demonstrates the application of deep learning to medical imaging and classification tasks.\n"]},{"cell_type":"markdown","metadata":{"id":"dw_-hFm6bjY6"},"source":["## 🚀 Setting Up the Environment: Installing Packages and Connecting to Google Drive\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":85783,"status":"ok","timestamp":1732437296384,"user":{"displayName":"Alessandro","userId":"13573195732524414409"},"user_tz":-60},"id":"nSFqEXpz7qbQ","outputId":"8c44dc82-191d-48d3-bd90-10e4d168710b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tensorflow==2.17.0\n","  Downloading tensorflow-2.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n","Collecting keras==3.4.1\n","  Downloading keras-3.4.1-py3-none-any.whl.metadata (5.8 kB)\n","Collecting tensorflow-decision-forests==1.10.0\n","  Downloading tensorflow_decision_forests-1.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.0 kB)\n","Collecting tensorflow-text==2.17.0\n","  Downloading tensorflow_text-2.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n","Requirement already satisfied: tf-keras==2.17.0 in /usr/local/lib/python3.10/dist-packages (2.17.0)\n","Collecting keras_cv\n","  Downloading keras_cv-0.9.0-py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (0.2.0)\n","Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (3.12.1)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (18.1.1)\n","Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (0.4.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (24.2)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (4.25.5)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (2.32.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (75.1.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (2.5.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (4.12.2)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (1.16.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (1.68.0)\n","Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (2.17.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (0.37.1)\n","Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.17.0) (1.26.4)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras==3.4.1) (13.9.4)\n","Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras==3.4.1) (0.0.8)\n","Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras==3.4.1) (0.13.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from tensorflow-decision-forests==1.10.0) (2.2.2)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from tensorflow-decision-forests==1.10.0) (0.45.0)\n","Collecting wurlitzer (from tensorflow-decision-forests==1.10.0)\n","  Downloading wurlitzer-3.1.1-py3-none-any.whl.metadata (2.5 kB)\n","Collecting ydf (from tensorflow-decision-forests==1.10.0)\n","  Downloading ydf-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n","Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from keras_cv) (2024.9.11)\n","Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.10/dist-packages (from keras_cv) (4.9.7)\n","Collecting keras-core (from keras_cv)\n","  Downloading keras_core-0.1.7-py3-none-any.whl.metadata (4.3 kB)\n","Requirement already satisfied: kagglehub in /usr/local/lib/python3.10/dist-packages (from keras_cv) (0.3.4)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.17.0) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.17.0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.17.0) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.17.0) (2024.8.30)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow==2.17.0) (3.7)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow==2.17.0) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow==2.17.0) (3.1.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kagglehub->keras_cv) (4.66.6)\n","Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from keras-core->keras_cv) (0.1.8)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->tensorflow-decision-forests==1.10.0) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->tensorflow-decision-forests==1.10.0) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->tensorflow-decision-forests==1.10.0) (2024.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras==3.4.1) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras==3.4.1) (2.18.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (8.1.7)\n","Requirement already satisfied: immutabledict in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (4.2.1)\n","Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (2.3)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (5.9.5)\n","Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (17.0.0)\n","Requirement already satisfied: simple-parsing in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (0.1.6)\n","Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (1.13.1)\n","Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (0.10.2)\n","Requirement already satisfied: array-record>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (0.5.1)\n","Requirement already satisfied: etils>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets->keras_cv) (1.10.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets->keras_cv) (2024.10.0)\n","Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets->keras_cv) (6.4.5)\n","Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets->keras_cv) (3.21.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras==3.4.1) (0.1.2)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow==2.17.0) (3.0.2)\n","Requirement already satisfied: docstring-parser<1.0,>=0.15 in /usr/local/lib/python3.10/dist-packages (from simple-parsing->tensorflow-datasets->keras_cv) (0.16)\n","Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-metadata->tensorflow-datasets->keras_cv) (1.66.0)\n","Downloading tensorflow-2.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (601.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m601.3/601.3 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading keras-3.4.1-py3-none-any.whl (1.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tensorflow_decision_forests-1.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.5/15.5 MB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tensorflow_text-2.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading keras_cv-0.9.0-py3-none-any.whl (650 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m650.7/650.7 kB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading keras_core-0.1.7-py3-none-any.whl (950 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m950.8/950.8 kB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading wurlitzer-3.1.1-py3-none-any.whl (8.6 kB)\n","Downloading ydf-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.3/9.3 MB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: ydf, wurlitzer, keras-core, keras, tensorflow, tensorflow-text, tensorflow-decision-forests, keras_cv\n","  Attempting uninstall: keras\n","    Found existing installation: keras 3.5.0\n","    Uninstalling keras-3.5.0:\n","      Successfully uninstalled keras-3.5.0\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.17.1\n","    Uninstalling tensorflow-2.17.1:\n","      Successfully uninstalled tensorflow-2.17.1\n","Successfully installed keras-3.4.1 keras-core-0.1.7 keras_cv-0.9.0 tensorflow-2.17.0 tensorflow-decision-forests-1.10.0 tensorflow-text-2.17.0 wurlitzer-3.1.1 ydf-0.8.0\n"]}],"source":["!pip install tensorflow==2.17.0 keras==3.4.1 tensorflow-decision-forests==1.10.0 tensorflow-text==2.17.0 tf-keras==2.17.0 keras_cv"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CO6_Ft_8T56A"},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras as tfk\n","from tensorflow.keras import layers as tfkl\n","import keras_cv\n","\n","import numpy as np\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","\n","\"\"\"np.random.seed(42)\n","tf.random.set_seed(42);\"\"\"\n","\n","np.random.seed(11)\n","tf.random.set_seed(11);"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17344,"status":"ok","timestamp":1732437330962,"user":{"displayName":"Alessandro","userId":"13573195732524414409"},"user_tz":-60},"id":"3wAm_kLONkFh","outputId":"34d58e34-4d0b-4634-a21f-4349a4ac3542"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /gdrive\n","/gdrive/My Drive/[2024-2025] AN2DL/Homework 1/Base_3\n"]}],"source":["from google.colab import drive\n","drive.mount('/gdrive')\n","%cd /gdrive/My Drive/[2024-2025] AN2DL/Homework 1/Base_3"]},{"cell_type":"markdown","metadata":{"id":"GN_cpHlSboXV"},"source":["## ⏳ Load the Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pLaoDaG1V1Yg"},"outputs":[],"source":["# Load the dataset\n","#data = np.load('training_set.npz')\n","#data = np.load('dataset_augmented_10k.npz')\n","data = np.load('dataset_augmented_default.npz')\n","x_train = data['images']\n","y_train = data['labels']\n","\n","data_original = np.load('training_set.npz')\n","x_test = data_original['images']\n","y_test = data_original['labels']"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1239,"status":"ok","timestamp":1732437446306,"user":{"displayName":"Alessandro","userId":"13573195732524414409"},"user_tz":-60},"id":"rJesjkncAkkR","outputId":"2426dd4d-7fa8-4990-94b1-fdaee4888a03"},"outputs":[{"output_type":"stream","name":"stdout","text":["Initial length is 20776 and 20776\n","Len: 20776\n"," Shape: (20776, 96, 96, 3)\n","\n","Len: 20776\n"," Shape: (20776, 8)\n","\n","Len: 11943\n"," Shape: (11943, 96, 96, 3)\n","\n","Len: 11943\n"," Shape: (11943, 1)\n","\n"]}],"source":["import hashlib\n","\n","# Get the hash of a certain image\n","def image_hash(image):\n","  image_bytes = image.tobytes()\n","  return hashlib.sha256(image_bytes).hexdigest()\n","\n","print(f\"Initial length is {len(x_train)} and {len(y_train)}\")\n","\n","# Remove all duplicates\n","def remove_duplicates(x_train, y_train):\n","  unique_images = []\n","  unique_labels = []\n","  duplicate_positions = set()\n","\n","  seen_hashes = {}\n","\n","  for i in range(len(x_train)):\n","      img_hash = image_hash(x_train[i])\n","      if img_hash not in seen_hashes:\n","        if i not in duplicate_positions:\n","          unique_images.append(x_train[i])\n","          unique_labels.append(y_train[i])\n","        seen_hashes[img_hash] = i\n","      else:\n","        duplicate_positions.add(seen_hashes[img_hash])\n","        duplicate_positions.add(i)\n","\n","  x_train = [x_train[i] for i in range(len(x_train)) if i not in duplicate_positions]\n","  y_train = [y_train[i] for i in range(len(y_train)) if i not in duplicate_positions]\n","\n","  x_train = np.array(x_train)\n","  y_train = np.array(y_train)\n","\n","  return x_train, y_train\n","\n","#x_train, y_train = remove_duplicates(x_train, y_train)\n","\n","x_test, y_test = remove_duplicates(x_test, y_test)\n","\n","print(f\"Len: {len(x_train)}\\n Shape: {x_train.shape}\\n\")\n","print(f\"Len: {len(y_train)}\\n Shape: {y_train.shape}\\n\")\n","print(f\"Len: {len(x_test)}\\n Shape: {x_test.shape}\\n\")\n","print(f\"Len: {len(y_test)}\\n Shape: {y_test.shape}\\n\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":104},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1732437446306,"user":{"displayName":"Alessandro","userId":"13573195732524414409"},"user_tz":-60},"id":"_yI2adyA44-y","outputId":"d652932d-b5aa-423f-ea7c-51fe708d6178"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'# Define a basic set of transformations 1\\ndata_augmentation = keras_cv.layers.Augmenter(\\n  layers = [\\n    layers.RandomFlip(\"horizontal_and_vertical\"),\\n    layers.RandomRotation(0.2),\\n    layers.RandomZoom(0.1),\\n    layers.RandomTranslation(0.1, 0.1),\\n    layers.RandomContrast(0.2),\\n  ]\\n)\\n\\n# Extract unique classes and their counts\\nunique, counts = np.unique(y_train, return_counts=True)\\nclass_counts = dict(zip(unique, counts))\\nprint(\"Original distribution:\", class_counts)\\n\\n# Maximum number of samples for a class\\nmax_samples = max(class_counts.values())\\n\\ndef make_balanced_with_augmented(x_train, y_train):\\n\\n  # New balanced dataset\\n  x_balanced = []\\n  y_balanced = []\\n\\n  # Oversampling for each class\\n  for cls in class_counts:\\n    # Filter samples for the current class\\n    x_class = x_train[np.where(y_train == cls)[0]]\\n    y_class = y_train[y_train == cls]\\n\\n    # Calculate the number of samples to add\\n    samples_to_add = max_samples - len(x_class)\\n\\n    if samples_to_add > 0:\\n      # Augment the samples to add\\n      augmented_images = []\\n      for _ in range(samples_to_add):\\n        augmented_image = data_augmentation(x_class[np.random.randint(len(x_class))][np.newaxis, ...])\\n        augmented_images.append(augmented_image.numpy()[0])\\n\\n      # Add the original and augmented samples to the balanced dataset\\n      x_balanced.append(np.concatenate([x_class, np.array(augmented_images)]))\\n      y_balanced.append(np.concatenate([y_class, np.full(samples_to_add, cls)]))\\n    else:\\n      # Add the original samples to the balanced dataset (if no oversampling is needed)\\n      x_balanced.append(x_class)\\n      y_balanced.append(y_class)\\n\\n  # Concatenate the balanced dataset\\n  x_train = np.concatenate(x_balanced)\\n  y_train = np.concatenate(y_balanced)\\n\\n  return x_train, y_train\\n\\nx_train, y_train = make_balanced_with_augmented(x_train, y_train)\\n\\n# Check the new distribution\\nunique_balanced, counts_balanced = np.unique(y_train, return_counts=True)\\nclass_counts_balanced = dict(zip(unique_balanced, counts_balanced))\\nprint(\"Balanced distribution of classes:\", class_counts_balanced)\\nprint(f\"New total number of sample is {len(x_train)}\")'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":10}],"source":["from keras import layers\n","\n","\"\"\"# Define a basic set of transformations 1\n","data_augmentation = keras_cv.layers.Augmenter(\n","  layers = [\n","    layers.RandomFlip(\"horizontal_and_vertical\"),\n","    layers.RandomRotation(0.2),\n","    layers.RandomZoom(0.1),\n","    layers.RandomTranslation(0.1, 0.1),\n","    layers.RandomContrast(0.2),\n","  ]\n",")\n","\n","# Extract unique classes and their counts\n","unique, counts = np.unique(y_train, return_counts=True)\n","class_counts = dict(zip(unique, counts))\n","print(\"Original distribution:\", class_counts)\n","\n","# Maximum number of samples for a class\n","max_samples = max(class_counts.values())\n","\n","def make_balanced_with_augmented(x_train, y_train):\n","\n","  # New balanced dataset\n","  x_balanced = []\n","  y_balanced = []\n","\n","  # Oversampling for each class\n","  for cls in class_counts:\n","    # Filter samples for the current class\n","    x_class = x_train[np.where(y_train == cls)[0]]\n","    y_class = y_train[y_train == cls]\n","\n","    # Calculate the number of samples to add\n","    samples_to_add = max_samples - len(x_class)\n","\n","    if samples_to_add > 0:\n","      # Augment the samples to add\n","      augmented_images = []\n","      for _ in range(samples_to_add):\n","        augmented_image = data_augmentation(x_class[np.random.randint(len(x_class))][np.newaxis, ...])\n","        augmented_images.append(augmented_image.numpy()[0])\n","\n","      # Add the original and augmented samples to the balanced dataset\n","      x_balanced.append(np.concatenate([x_class, np.array(augmented_images)]))\n","      y_balanced.append(np.concatenate([y_class, np.full(samples_to_add, cls)]))\n","    else:\n","      # Add the original samples to the balanced dataset (if no oversampling is needed)\n","      x_balanced.append(x_class)\n","      y_balanced.append(y_class)\n","\n","  # Concatenate the balanced dataset\n","  x_train = np.concatenate(x_balanced)\n","  y_train = np.concatenate(y_balanced)\n","\n","  return x_train, y_train\n","\n","x_train, y_train = make_balanced_with_augmented(x_train, y_train)\n","\n","# Check the new distribution\n","unique_balanced, counts_balanced = np.unique(y_train, return_counts=True)\n","class_counts_balanced = dict(zip(unique_balanced, counts_balanced))\n","print(\"Balanced distribution of classes:\", class_counts_balanced)\n","print(f\"New total number of sample is {len(x_train)}\")\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1732437446306,"user":{"displayName":"Alessandro","userId":"13573195732524414409"},"user_tz":-60},"id":"KIA7fJLg44-y","colab":{"base_uri":"https://localhost:8080/"},"outputId":"7c8a936e-fec5-4367-bdcf-e932feefc89b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Len: 20776\n"," Shape: (20776, 96, 96, 3)\n","\n","Len: 20776\n"," Shape: (20776, 8)\n","\n","Len: 11943\n"," Shape: (11943, 96, 96, 3)\n","\n","Len: 11943\n"," Shape: (11943, 8)\n","\n"]}],"source":["# Converti y in one-hot encoding\n","#y_train = tf.keras.utils.to_categorical(y_train, num_classes=8)\n","#y_train = tf.keras.utils.to_categorical(y_train, num_classes=8)\n","#y_test2 = tf.keras.utils.to_categorical(y_test2, num_classes=8)\n","\n","y_test = tf.keras.utils.to_categorical(y_test, num_classes=8)\n","\n","print(f\"Len: {len(x_train)}\\n Shape: {x_train.shape}\\n\")\n","print(f\"Len: {len(y_train)}\\n Shape: {y_train.shape}\\n\")\n","print(f\"Len: {len(x_test)}\\n Shape: {x_test.shape}\\n\")\n","print(f\"Len: {len(y_test)}\\n Shape: {y_test.shape}\\n\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5FxPNaJEa8RC"},"outputs":[],"source":["# split train in training and test set\n","#x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.1, random_state=42)\n","#x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.1, random_state=99)\n","### x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.1, random_state=11)"]},{"cell_type":"markdown","metadata":{"id":"Vm3FHPFD44-z"},"source":["# Preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1732437446306,"user":{"displayName":"Alessandro","userId":"13573195732524414409"},"user_tz":-60},"id":"Wf3_Ii2J44-z","colab":{"base_uri":"https://localhost:8080/","height":70},"outputId":"ab1918ef-b08c-44db-9ce3-2019ef247331"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'def augment(images, labels):\\n  augmenter = keras_cv.layers.Augmenter(\\n    layers = [\\n      keras_cv.layers.RandomFlip(\\n          mode=\"horizontal_and_vertical\"\\n      ),\\n      keras_cv.layers.RandomRotation(\\n          factor=0.2,\\n          fill_mode=\\'nearest\\'\\n      ),\\n      keras_cv.layers.MixUp(\\n          alpha=0.5,\\n      ),\\n      keras_cv.layers.CutMix(\\n          alpha=0.5\\n      ),\\n    ]\\n  )\\n\\n  inputs = {\"images\": images, \"labels\": labels}\\n  output = augmenter(inputs)\\n  return output[\"images\"], output[\"labels\"]'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":13}],"source":["# Function to get a set of layers for augmentation 2\n","\"\"\"def augment(images, labels):\n","  augmenter = keras_cv.layers.Augmenter(\n","    layers = [\n","      keras_cv.layers.RandomFlip(\n","          mode=\"horizontal_and_vertical\"\n","      ),\n","      keras_cv.layers.RandomRotation(\n","          factor=0.2,\n","          fill_mode='nearest'\n","      ),\n","      keras_cv.layers.MixUp(\n","          alpha=0.5,\n","      ),\n","      keras_cv.layers.CutMix(\n","          alpha=0.5\n","      ),\n","    ]\n","  )\n","\n","  inputs = {\"images\": images, \"labels\": labels}\n","  output = augmenter(inputs)\n","  return output[\"images\"], output[\"labels\"]\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1732437446306,"user":{"displayName":"Alessandro","userId":"13573195732524414409"},"user_tz":-60},"id":"uGFIStLM44-0","colab":{"base_uri":"https://localhost:8080/","height":70},"outputId":"54383b0e-ac44-42ab-e684-4b5f7cc78ce3"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'def sample_random_images(dataset, sample_size=5):\\n    random_samples = dataset.shuffle(buffer_size=1000).take(sample_size)\\n    images = []\\n    labels = []\\n    for image, label in random_samples:\\n        images.append(image.numpy())\\n        labels.append(label.numpy())\\n    return tf.convert_to_tensor(images), tf.convert_to_tensor(labels)\\n\\n# Convert the previously constructed data into tf.data.Dataset\\nx_train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":14}],"source":["# This function returns random (image, label) pairs\n","\"\"\"def sample_random_images(dataset, sample_size=5):\n","    random_samples = dataset.shuffle(buffer_size=1000).take(sample_size)\n","    images = []\n","    labels = []\n","    for image, label in random_samples:\n","        images.append(image.numpy())\n","        labels.append(label.numpy())\n","    return tf.convert_to_tensor(images), tf.convert_to_tensor(labels)\n","\n","# Convert the previously constructed data into tf.data.Dataset\n","x_train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":70},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1732437446306,"user":{"displayName":"Alessandro","userId":"13573195732524414409"},"user_tz":-60},"id":"nts2hQk944-0","outputId":"daa12bde-ff01-44a7-ebb9-b4c6140c7be5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'# We take 4000 random images and augment them\\nsample_size = 4000\\nrandom_x, random_y = sample_random_images(x_train_dataset, sample_size)\\nprint(f\"{len(random_x)} {len(random_y)}\")\\naug_images, aug_labels = augment(random_x, random_y)\\n\\n# We concatenate these 4000 new augmented pictures to the originale dataset\\nx_train = tf.concat([x_train, aug_images], axis=0)\\ny_train = tf.concat([y_train, aug_labels], axis=0)\\n\\nprint(x_train.shape)\\nprint(y_train.shape)\\n\\ndel random_x\\ndel random_y'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":15}],"source":["\"\"\"# We take 4000 random images and augment them\n","sample_size = 4000\n","random_x, random_y = sample_random_images(x_train_dataset, sample_size)\n","print(f\"{len(random_x)} {len(random_y)}\")\n","aug_images, aug_labels = augment(random_x, random_y)\n","\n","# We concatenate these 4000 new augmented pictures to the originale dataset\n","x_train = tf.concat([x_train, aug_images], axis=0)\n","y_train = tf.concat([y_train, aug_labels], axis=0)\n","\n","print(x_train.shape)\n","print(y_train.shape)\n","\n","del random_x\n","del random_y\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1732437446306,"user":{"displayName":"Alessandro","userId":"13573195732524414409"},"user_tz":-60},"id":"290GYoe1R7Y-","colab":{"base_uri":"https://localhost:8080/","height":104},"outputId":"5f80a51a-90bf-457a-acc8-35db2c281cbb"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'def apply_augmentation(image, is_randaugment):\\n    if is_randaugment:\\n        return apply_randaugment(image)\\n    else:\\n        return apply_augmix(image)\\n\\ndef apply_augmix(image):\\n    return augmix(image)\\n\\ndef apply_randaugment(image):\\n    return randaugmenter(image)\\n\\nrandaugmenter = tf.keras.Sequential(\\n    [\\n        keras_cv.layers.RandAugment([0, 255], 3, 0.5), # it was 0.4 instead of 0.5\\n    ]\\n)\\n\\naugmix = tf.keras.Sequential(\\n    [\\n        keras_cv.layers.AugMix([0, 255], 0.4), # no number was set for severity, so it was 0.3\\n    ]\\n)\\n\\nbatch_size = 256\\nhalf_size = len(x_train) // 2\\n\\n# We apply the RandAugment augmentation to the first half of the dataset\\ndataset_randaugment = tf.data.Dataset.from_tensor_slices(x_train[:half_size])\\ndataset_randaugment = dataset_randaugment.map(lambda x: apply_augmentation(x, is_randaugment=True), num_parallel_calls=tf.data.AUTOTUNE)\\n\\n# We apply the AugMix augmentation to the second half of the dataset\\ndataset_augmix = tf.data.Dataset.from_tensor_slices(x_train[half_size:])\\ndataset_augmix = dataset_augmix.map(lambda x: apply_augmentation(x, is_randaugment=False), num_parallel_calls=tf.data.AUTOTUNE)\\n\\ndataset = dataset_randaugment.concatenate(dataset_augmix)\\ndataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\\n\\nx_train = tf.concat([batch for batch in dataset], axis=0)\\n\\ndel x_train_dataset'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":16}],"source":["\"\"\"def apply_augmentation(image, is_randaugment):\n","    if is_randaugment:\n","        return apply_randaugment(image)\n","    else:\n","        return apply_augmix(image)\n","\n","def apply_augmix(image):\n","    return augmix(image)\n","\n","def apply_randaugment(image):\n","    return randaugmenter(image)\n","\n","randaugmenter = tf.keras.Sequential(\n","    [\n","        keras_cv.layers.RandAugment([0, 255], 3, 0.5), # it was 0.4 instead of 0.5\n","    ]\n",")\n","\n","augmix = tf.keras.Sequential(\n","    [\n","        keras_cv.layers.AugMix([0, 255], 0.4), # no number was set for severity, so it was 0.3\n","    ]\n",")\n","\n","batch_size = 256\n","half_size = len(x_train) // 2\n","\n","# We apply the RandAugment augmentation to the first half of the dataset\n","dataset_randaugment = tf.data.Dataset.from_tensor_slices(x_train[:half_size])\n","dataset_randaugment = dataset_randaugment.map(lambda x: apply_augmentation(x, is_randaugment=True), num_parallel_calls=tf.data.AUTOTUNE)\n","\n","# We apply the AugMix augmentation to the second half of the dataset\n","dataset_augmix = tf.data.Dataset.from_tensor_slices(x_train[half_size:])\n","dataset_augmix = dataset_augmix.map(lambda x: apply_augmentation(x, is_randaugment=False), num_parallel_calls=tf.data.AUTOTUNE)\n","\n","dataset = dataset_randaugment.concatenate(dataset_augmix)\n","dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n","\n","x_train = tf.concat([batch for batch in dataset], axis=0)\n","\n","del x_train_dataset\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":104},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1732437446306,"user":{"displayName":"Alessandro","userId":"13573195732524414409"},"user_tz":-60},"id":"LolaIQ1E44-0","outputId":"e110574c-8367-4676-bcb0-5e82d6309ce5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'# We define a new set of augmentations 3\\naugmenter = keras_cv.layers.Augmenter(\\n  layers = [\\n    keras_cv.layers.RandAugment([0, 255], 3, 0.5),\\n    keras_cv.layers.AugMix([0, 255], 0.4),\\n\\n    keras_cv.layers.RandomCutout(0.075, 0.075, fill_mode=\"gaussian_noise\"),\\n    keras_cv.layers.RandomCutout(0.075, 0.075, fill_mode=\"gaussian_noise\"),\\n    keras_cv.layers.RandomCutout(0.075, 0.075, fill_mode=\"gaussian_noise\"),\\n    keras_cv.layers.RandomCutout(0.075, 0.075, fill_mode=\"gaussian_noise\"),\\n    keras_cv.layers.RandomCutout(0.075, 0.075, fill_mode=\"gaussian_noise\"),\\n  ]\\n)\\n\\n# And again we apply this new augmenter to other 7000 images\\nsample_size = 7000\\nrandom_x, random_y = sample_random_images(dataset, sample_size)\\n#del dataset\\nrandom_y = tf.cast(random_y, dtype=tf.float32)\\naug_images = augmenter(random_x)\\n\\nx_train = tf.concat([x_train, aug_images], axis=0)\\ny_train = tf.concat([y_train, random_y], axis=0)\\n\\nx_train = x_train.numpy()\\ny_train = y_train.numpy()\\n\\n######### print(x_train.shape)\\n######### print(aug_images.shape)\\n######### print(random_y.shape)\\n\\nx_train=tf.cast(x_train, dtype=tf.float32)\\n\\nnp.savez_compressed(\\'dataset_augmented_default.npz\\', images=x_train, labels=y_train)\\n\\nprint(x_train.shape)'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":17}],"source":["\"\"\"# We define a new set of augmentations 3\n","augmenter = keras_cv.layers.Augmenter(\n","  layers = [\n","    keras_cv.layers.RandAugment([0, 255], 3, 0.5),\n","    keras_cv.layers.AugMix([0, 255], 0.4),\n","\n","    keras_cv.layers.RandomCutout(0.075, 0.075, fill_mode=\"gaussian_noise\"),\n","    keras_cv.layers.RandomCutout(0.075, 0.075, fill_mode=\"gaussian_noise\"),\n","    keras_cv.layers.RandomCutout(0.075, 0.075, fill_mode=\"gaussian_noise\"),\n","    keras_cv.layers.RandomCutout(0.075, 0.075, fill_mode=\"gaussian_noise\"),\n","    keras_cv.layers.RandomCutout(0.075, 0.075, fill_mode=\"gaussian_noise\"),\n","  ]\n",")\n","\n","# And again we apply this new augmenter to other 7000 images\n","sample_size = 7000\n","random_x, random_y = sample_random_images(dataset, sample_size)\n","#del dataset\n","random_y = tf.cast(random_y, dtype=tf.float32)\n","aug_images = augmenter(random_x)\n","\n","x_train = tf.concat([x_train, aug_images], axis=0)\n","y_train = tf.concat([y_train, random_y], axis=0)\n","\n","x_train = x_train.numpy()\n","y_train = y_train.numpy()\n","\n","######### print(x_train.shape)\n","######### print(aug_images.shape)\n","######### print(random_y.shape)\n","\n","x_train=tf.cast(x_train, dtype=tf.float32)\n","\n","np.savez_compressed('dataset_augmented_default.npz', images=x_train, labels=y_train)\n","\n","print(x_train.shape)\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1732437446306,"user":{"displayName":"Alessandro","userId":"13573195732524414409"},"user_tz":-60},"id":"J2Q6-Qdm44-2","outputId":"7387b880-6e7f-44ba-99c4-7af54b1a0ca4"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"# We show an image with the latest augmentation (3)\\nplt.imshow(x_train[-4] / 255.0)\\nprint('Class', aug_labels[1])\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":18}],"source":["import matplotlib.pyplot as plt\n","\n","\"\"\"# We show an image with the latest augmentation (3)\n","plt.imshow(x_train[-4] / 255.0)\n","print('Class', aug_labels[1])\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rZiX8emjBZ3U"},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","import keras_cv\n","from tensorflow import keras as tfk\n","from tensorflow.keras import layers, models, applications\n","from tensorflow.keras.callbacks import LambdaCallback\n","import random\n","import keras\n","from keras.saving import register_keras_serializable\n","from sklearn.utils.class_weight import compute_class_weight\n","\n","def spatial_attention(input_tensor):\n","    \"\"\"\n","    Spatial Attention Block.\n","\n","    Args:\n","        input_tensor (tf.Tensor): Input feature map, shape (batch, height, width, channels).\n","\n","    Returns:\n","        tf.Tensor: Output tensor after applying spatial attention.\n","    \"\"\"\n","    # Media e massimo pooling lungo l'asse dei canali come livelli Keras\n","    avg_pool = tfk.layers.Lambda(lambda x: tf.reduce_mean(x, axis=-1, keepdims=True))(input_tensor)\n","    max_pool = tfk.layers.Lambda(lambda x: tf.reduce_max(x, axis=-1, keepdims=True))(input_tensor)\n","\n","    # Concatenazione delle due mappe di attenzione\n","    concat = tfk.layers.Concatenate(axis=-1)([avg_pool, max_pool])  # Shape: (batch, height, width, 2)\n","\n","    # Convoluzione per generare la mappa di attenzione spaziale\n","    attention = tfk.layers.Conv2D(1, kernel_size=7, padding='same', activation='sigmoid')(concat)  # Shape: (batch, height, width, 1)\n","\n","    # Scala l'input con la mappa di attenzione\n","    output = tfk.layers.Multiply()([input_tensor, attention])  # Shape: (batch, height, width, channels)\n","\n","    return output"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OM8fYnpvNza0"},"outputs":[],"source":["# These were initially inside the get augmetnation layer\n","\n","\"\"\"\"\"\"\n","\n","class MyModel:\n","    def __init__(self):\n","        \"\"\"\n","        Inizializza lo stato interno del modello pretrained.\n","        \"\"\"\n","        self.strategy = tf.distribute.MirroredStrategy()\n","        self.neural_network = self.create_model()\n","\n","    def get_augmentation_layer(self):\n","        return tf.keras.Sequential([\n","\n","            # Random rotation\n","            keras.layers.RandomRotation(0.5, fill_mode='reflect'),\n","\n","            # Random zoom in height\n","            keras.layers.RandomZoom(height_factor=(-0.2, 0.7), fill_mode='nearest'),\n","\n","            # Other types of augmentations\n","            keras.layers.RandomZoom(height_factor=(0.0, 0.0), width_factor=(-0.3, 0.3), fill_mode='nearest'),\n","            keras.layers.RandomFlip(mode=\"horizontal\"),\n","            keras.layers.RandomFlip(mode=\"vertical\"),\n","            keras.layers.RandomTranslation(height_factor=(-0.2, 0.2), width_factor=(-0.2, 0.2)),\n","\n","            keras.layers.RandomBrightness(0.3),\n","            #keras_cv.layers.RandomHue(0.3, [0,255]),\n","            keras_cv.layers.RandomContrast([0, 255], 0.3),\n","            keras_cv.layers.RandomGaussianBlur(2, 2),\n","            #keras_cv.layers.RandomCutout(0.3, 0.3,\"gaussian_noise\"),\n","\n","            # Adding Gaussian noise\n","            keras.layers.GaussianNoise(0.07)\n","\n","        ])\n","\n","\n","    def create_model(self):\n","        \"\"\"\n","        Crea e restituisce un modello\n","        \"\"\"\n","        # Definisci i layer di data augmentation\n","        data_augmentation = self.get_augmentation_layer()\n","\n","        with self.strategy.scope():\n","\n","            # Utilizza una rete pre-addestrata\n","            #model_pretrained = tfk.applications.ConvNeXtBase(\n","            model_pretrained = tfk.applications.ConvNeXtXLarge(\n","                input_shape=(96, 96, 3),\n","                include_top=False,\n","                weights='imagenet',\n","                pooling=None\n","            )\n","            #self.model_name_pretrained = 'convnext_base'\n","            self.model_name_pretrained = 'convnext_xlarge'\n","\n","            print(\"number of layers:\")\n","            print(len(model_pretrained.layers))\n","\n","            # Costruisci il modello\n","            inputs = tfk.Input(shape=(96, 96, 3), name='input_layer')\n","            x = data_augmentation(inputs)\n","            x = model_pretrained(x)\n","\n","            # Batch Normalization dopo il modello pre-addestrato\n","            x = tfk.layers.BatchNormalization()(x)\n","\n","            # Squeeze-and-Excitation (SE Block)\n","            se = tfk.layers.GlobalAveragePooling2D()(x)  # Riduce a (batch_size, channels)\n","            se = tfk.layers.Dense(se.shape[-1] // 16, activation='relu')(se)  # Compress\n","            se = tfk.layers.Dense(se.shape[-1] * 16, activation='sigmoid')(se)  # Expand\n","            x = tfk.layers.Multiply()([x, tfk.layers.Reshape((1, 1, -1))(se)])  # Scala i canali\n","\n","            # Global Pooling (per ridurre la dimensionalità)\n","            x = tfk.layers.GlobalAveragePooling2D()(x)\n","\n","            # Livelli Fully Connected con Batch Normalization e Leaky ReLU\n","            x = tfk.layers.Dense(512)(x)\n","            x = tfk.layers.BatchNormalization()(x)\n","            x = tfk.layers.LeakyReLU(alpha=0.1)(x)\n","            x = tfk.layers.Dropout(0.3)(x)\n","\n","            x = tfk.layers.Dense(256)(x)\n","            x = tfk.layers.BatchNormalization()(x)\n","            x = tfk.layers.LeakyReLU(alpha=0.1)(x)\n","            x = tfk.layers.Dropout(0.3)(x)\n","\n","            outputs = tfk.layers.Dense(8, activation='softmax', name='output_layer')(x)\n","\n","            model = tfk.Model(inputs=inputs, outputs=outputs, name='model')\n","\n","            return model\n","\n","    def train_transfer_learning(self, X_train, y_train, X_test, y_test, epochs=10, batch_size=32):\n","        \"\"\"\n","        Pre-addestra il modello con i layer congelati.\n","        \"\"\"\n","\n","        with self.strategy.scope():  # Ensure training happens inside strategy scope\n","\n","            self.neural_network.get_layer(self.model_name_pretrained).trainable = False\n","\n","            # Sblocca i layer convoluzionali dal layer `fine_tune_from` in poi\n","            for i, layer in enumerate(self.neural_network.get_layer(self.model_name_pretrained).layers):\n","                layer.trainable = False\n","\n","            # Ricompila il modello (necessario dopo aver modificato i layer trainabili)\n","            self.neural_network.compile(\n","                loss=tfk.losses.CategoricalCrossentropy(),\n","                optimizer=tfk.optimizers.Lion(learning_rate=1e-3),\n","                metrics=['accuracy']\n","            )\n","\n","\n","            # Callback\n","            save_every_5 = LambdaCallback(\n","                on_epoch_end=lambda epoch, logs:\n","                self.neural_network.save(f'model_epoch_{epoch + 1}.keras') if (epoch + 1) % 5 == 0 else None\n","            )\n","            early_stopping = tfk.callbacks.EarlyStopping(\n","                monitor='val_accuracy',\n","                mode='max',\n","                patience=8,\n","                restore_best_weights=True\n","            )\n","\n","            # Riaddestra il modello\n","            history = self.neural_network.fit(\n","                X_train,\n","                y_train,\n","                batch_size=batch_size,\n","                epochs=epochs,\n","                shuffle=True,\n","                validation_data=(X_test, y_test),\n","                callbacks=[save_every_5, early_stopping]\n","            )\n","\n","    def train_fine_tuning(self, X_train, y_train, X_test, y_test, epochs=10, batch_size=32, fine_tune_from=50):\n","        \"\"\"\n","        Sblocca i layer selezionati e riaddestra il modello.\n","        \"\"\"\n","\n","        with self.strategy.scope():  # Ensure training happens inside strategy scope\n","\n","            self.neural_network.get_layer(self.model_name_pretrained).trainable = True\n","\n","            # Sblocca i layer convoluzionali dal layer `fine_tune_from` in poi\n","            for i, layer in enumerate(self.neural_network.get_layer(self.model_name_pretrained).layers):\n","                layer.trainable = False\n","                if i > fine_tune_from:\n","                  if isinstance(layer, tf.keras.layers.Conv2D) or isinstance(layer, tf.keras.layers.DepthwiseConv2D):\n","                    print(True)\n","                    layer.trainable = True\n","\n","\n","            # Ricompila il modello con un learning rate più basso\n","            self.neural_network.compile(\n","                loss=tfk.losses.CategoricalCrossentropy(),\n","                #optimizer=tfk.optimizers.Lion(learning_rate=1e-4),\n","                optimizer=tfk.optimizers.Lion(learning_rate=1e-3),\n","                metrics=['accuracy']\n","            )\n","\n","            # Callback\n","            save_every_5 = LambdaCallback(\n","                on_epoch_end=lambda epoch, logs:\n","                self.neural_network.save(f'model_epoch_{epoch + 1}.keras') if (epoch + 1) % 5 == 0 else None\n","            )\n","            early_stopping = tfk.callbacks.EarlyStopping(\n","                monitor='val_accuracy',\n","                mode='max',\n","                patience=8,\n","                restore_best_weights=True\n","            )\n","\n","\n","            # Riaddestra il modello\n","            history = self.neural_network.fit(\n","                X_train,\n","                y_train,\n","                batch_size=batch_size,\n","                epochs=epochs,\n","                shuffle=True,\n","                validation_data=(X_test, y_test),\n","                callbacks=[save_every_5, early_stopping]\n","            )\n","\n","    def test(self, X_test, y_test):\n","        \"\"\"\n","        Valuta il modello sui dati di test X_test e le etichette y_test.\n","        \"\"\"\n","        test_loss, test_acc = self.neural_network.evaluate(X_test, y_test)\n","        print(f'Test accuracy: {test_acc}')\n","\n","    def load(self, path):\n","\n","        # Re-compile the model inside the strategy scope\n","        with self.strategy.scope():\n","            self.neural_network = tfk.models.load_model(path)\n","            self.neural_network.compile(\n","                loss=tfk.losses.CategoricalCrossentropy(),\n","                optimizer=tfk.optimizers.Lion(),  # Create optimizer inside the scope\n","                metrics=['accuracy']\n","            )\n","\n","    def save(self):\n","        \"\"\"\n","        Salva il modello senza i layer di data augmentation.\n","        \"\"\"\n","        self.neural_network.save('/gdrive/MyDrive/[2024-2025] AN2DL/Homework 1/Base_3/weights.keras')\n","\n","    def predict(self, X):\n","        \"\"\"\n","        Predice le etichette corrispondenti all'input X.\n","        \"\"\"\n","        preds = self.neural_network.predict(X)\n","        preds = np.argmax(preds, axis=1)\n","        return preds"]},{"cell_type":"markdown","metadata":{"id":"FSliIxBvbs2Q"},"source":["## 🛠️ Train and Save the Model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":72721,"status":"ok","timestamp":1732437519268,"user":{"displayName":"Alessandro","userId":"13573195732524414409"},"user_tz":-60},"id":"hHk2sh_qGXLw","outputId":"9eca1ebb-d9fb-4b6d-ca61-b08e04c7a62c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/convnext/convnext_xlarge_notop.h5\n","\u001b[1m1393257616/1393257616\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 0us/step\n","number of layers:\n","259\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n","  warnings.warn(\n"]}],"source":["model = MyModel()\n","\n","# Load the saved model\n","model_path = \"model_epoch_15.keras\"\n","with model.strategy.scope():\n","    loaded_network = tf.keras.models.load_model(model_path)\n","model.neural_network = loaded_network"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":70},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1732437519268,"user":{"displayName":"Alessandro","userId":"13573195732524414409"},"user_tz":-60},"id":"_IqqnFcq8KnX","outputId":"f6a6c2a7-c768-4e5c-ba4b-d67d131f80f5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'data_augmentation = model.get_augmentation_layer()\\n\\n# We apply the first set of augmentations to a random picture\\nrotated_image = data_augmentation(x_train[0])\\nprint(y_train[6001])\\n\\n# Show the original image as well as the rotated one\\nplt.figure(figsize=(10, 5))\\n\\n# Show the rotated image\\nplt.subplot(1, 2, 1)\\nplt.imshow(x_train[0] / 255.0)\\nplt.title(\"Immagine Ruotata\")\\nplt.axis(\\'off\\')\\n\\n\\'\\'\\'\\n# Mostra l\\'immagine ruotata\\nplt.subplot(1, 2, 2)\\nplt.imshow(rotated_image / 255.0)\\nplt.title(\"Immagine Ruotata\")\\nplt.axis(\\'off\\')\\'\\'\\'\\n\\nplt.show()'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":22}],"source":["import matplotlib.pyplot as plt\n","import keras_cv\n","\n","\"\"\"data_augmentation = model.get_augmentation_layer()\n","\n","# We apply the first set of augmentations to a random picture\n","rotated_image = data_augmentation(x_train[0])\n","print(y_train[6001])\n","\n","# Show the original image as well as the rotated one\n","plt.figure(figsize=(10, 5))\n","\n","# Show the rotated image\n","plt.subplot(1, 2, 1)\n","plt.imshow(x_train[0] / 255.0)\n","plt.title(\"Immagine Ruotata\")\n","plt.axis('off')\n","\n","'''\n","# Mostra l'immagine ruotata\n","plt.subplot(1, 2, 2)\n","plt.imshow(rotated_image / 255.0)\n","plt.title(\"Immagine Ruotata\")\n","plt.axis('off')'''\n","\n","plt.show()\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wJvoNKpU44-5"},"outputs":[],"source":["#model.load('/kaggle/working/model_epoch_10.keras')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dcVWLb-jGRd5"},"outputs":[],"source":["#x_test_augmented = model.get_augmentation_layer()(x_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1732437519268,"user":{"displayName":"Alessandro","userId":"13573195732524414409"},"user_tz":-60},"id":"somuYQZT44-5","outputId":"dfabc400-3269-4abc-82ff-a921218935a9"},"outputs":[{"output_type":"stream","name":"stdout","text":["float32\n"]}],"source":["print(x_train.dtype)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NfyHkIEQ44-6"},"outputs":[],"source":["#model.train_transfer_learning(x_train, y_train, x_test, y_test, 50, 512)\n","#model.train_transfer_learning(x_train, y_train, x_test, y_test, 1, 512)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TSm6IFUCP5Vh"},"outputs":[],"source":["#model.neural_network.save('weights_xl_1.keras')"]},{"cell_type":"code","source":["print(f\"Len: {len(x_train)}\\n Shape: {x_train.shape}\\n\")\n","print(f\"Len: {len(y_train)}\\n Shape: {y_train.shape}\\n\")\n","print(f\"Len: {len(x_test)}\\n Shape: {x_test.shape}\\n\")\n","print(f\"Len: {len(y_test)}\\n Shape: {y_test.shape}\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aYC5g8T9S2Op","executionInfo":{"status":"ok","timestamp":1732437519268,"user_tz":-60,"elapsed":4,"user":{"displayName":"Alessandro","userId":"13573195732524414409"}},"outputId":"4da2b508-6328-41a2-ef65-f54cec27d7a2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Len: 20776\n"," Shape: (20776, 96, 96, 3)\n","\n","Len: 20776\n"," Shape: (20776, 8)\n","\n","Len: 11943\n"," Shape: (11943, 96, 96, 3)\n","\n","Len: 11943\n"," Shape: (11943, 8)\n","\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"x5CJLeaw44-6","executionInfo":{"status":"error","timestamp":1732482094804,"user_tz":-60,"elapsed":44575540,"user":{"displayName":"Alessandro","userId":"13573195732524414409"}},"outputId":"6ce1ebf6-a841-4333-db91-c0e0d3166318"},"outputs":[{"output_type":"stream","name":"stdout","text":["True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","True\n","Epoch 1/50\n","\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2281s\u001b[0m 14s/step - accuracy: 0.8302 - loss: 0.5675 - val_accuracy: 0.9637 - val_loss: 0.1075\n","Epoch 2/50\n","\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2236s\u001b[0m 14s/step - accuracy: 0.8290 - loss: 0.5741 - val_accuracy: 0.9687 - val_loss: 0.0897\n","Epoch 3/50\n","\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2259s\u001b[0m 14s/step - accuracy: 0.8294 - loss: 0.5703 - val_accuracy: 0.9664 - val_loss: 0.0970\n","Epoch 4/50\n","\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2231s\u001b[0m 14s/step - accuracy: 0.8224 - loss: 0.5857 - val_accuracy: 0.9673 - val_loss: 0.0969\n","Epoch 5/50\n","\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2491s\u001b[0m 15s/step - accuracy: 0.8295 - loss: 0.5644 - val_accuracy: 0.9627 - val_loss: 0.1073\n","Epoch 6/50\n","\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2230s\u001b[0m 14s/step - accuracy: 0.8328 - loss: 0.5712 - val_accuracy: 0.9602 - val_loss: 0.1207\n","Epoch 7/50\n","\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2233s\u001b[0m 14s/step - accuracy: 0.8348 - loss: 0.5601 - val_accuracy: 0.9637 - val_loss: 0.1059\n","Epoch 8/50\n","\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2236s\u001b[0m 14s/step - accuracy: 0.8402 - loss: 0.5558 - val_accuracy: 0.9619 - val_loss: 0.1109\n","Epoch 9/50\n","\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2229s\u001b[0m 14s/step - accuracy: 0.8350 - loss: 0.5526 - val_accuracy: 0.9653 - val_loss: 0.1026\n","Epoch 10/50\n","\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2442s\u001b[0m 15s/step - accuracy: 0.8378 - loss: 0.5500 - val_accuracy: 0.9691 - val_loss: 0.0870\n","Epoch 11/50\n","\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2234s\u001b[0m 14s/step - accuracy: 0.8412 - loss: 0.5521 - val_accuracy: 0.9626 - val_loss: 0.1048\n","Epoch 12/50\n","\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2258s\u001b[0m 14s/step - accuracy: 0.8414 - loss: 0.5510 - val_accuracy: 0.9704 - val_loss: 0.0855\n","Epoch 13/50\n","\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2231s\u001b[0m 14s/step - accuracy: 0.8385 - loss: 0.5472 - val_accuracy: 0.9597 - val_loss: 0.1140\n","Epoch 14/50\n","\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2258s\u001b[0m 14s/step - accuracy: 0.8397 - loss: 0.5479 - val_accuracy: 0.9622 - val_loss: 0.1081\n","Epoch 15/50\n","\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2425s\u001b[0m 15s/step - accuracy: 0.8478 - loss: 0.5377 - val_accuracy: 0.9661 - val_loss: 0.1030\n","Epoch 16/50\n","\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2255s\u001b[0m 14s/step - accuracy: 0.8474 - loss: 0.5309 - val_accuracy: 0.9703 - val_loss: 0.0863\n","Epoch 17/50\n","\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2237s\u001b[0m 14s/step - accuracy: 0.8416 - loss: 0.5356 - val_accuracy: 0.9729 - val_loss: 0.0770\n","Epoch 18/50\n","\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2231s\u001b[0m 14s/step - accuracy: 0.8491 - loss: 0.5232 - val_accuracy: 0.9730 - val_loss: 0.0794\n","Epoch 19/50\n","\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2233s\u001b[0m 14s/step - accuracy: 0.8440 - loss: 0.5310 - val_accuracy: 0.9711 - val_loss: 0.0851\n","Epoch 20/50\n","\u001b[1m132/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m5:10\u001b[0m 10s/step - accuracy: 0.8469 - loss: 0.5264"]},{"output_type":"stream","name":"stderr","text":["ERROR:root:Internal Python error in the inspect module.\n","Below is the traceback from this internal error.\n","\n"]},{"output_type":"stream","name":"stdout","text":["Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"<ipython-input-29-4a6438a9a9f0>\", line 2, in <cell line: 2>\n","    model.train_fine_tuning(x_train, y_train, x_test, y_test, 50, 128, 150)\n","  File \"<ipython-input-20-22a9cb61a0d8>\", line 181, in train_fine_tuning\n","    history = self.neural_network.fit(\n","  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n","    return fn(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 318, in fit\n","    logs = self.train_function(iterator)\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n","    return fn(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 833, in __call__\n","    result = self._call(*args, **kwds)\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 878, in _call\n","    results = tracing_compilation.call_function(\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\", line 139, in call_function\n","    return function._call_flat(  # pylint: disable=protected-access\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\", line 1322, in _call_flat\n","    return self._inference_function.call_preflattened(args)\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 216, in call_preflattened\n","    flat_outputs = self.call_flat(*args)\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 251, in call_flat\n","    outputs = self._bound_context.call_function(\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\", line 1552, in call_function\n","    outputs = execute.execute(\n","  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\", line 53, in quick_execute\n","    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n","KeyboardInterrupt\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n","    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n","    return f(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n","    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n","  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n","    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n","  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n","    filename = getsourcefile(frame) or getfile(frame)\n","  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n","    module = getmodule(object, filename)\n","  File \"/usr/lib/python3.10/inspect.py\", line 875, in getmodule\n","    f = getabsfile(module)\n","  File \"/usr/lib/python3.10/inspect.py\", line 844, in getabsfile\n","    _filename = getsourcefile(object) or getfile(object)\n","  File \"/usr/lib/python3.10/inspect.py\", line 826, in getsourcefile\n","    if os.path.exists(filename):\n","  File \"/usr/lib/python3.10/genericpath.py\", line 19, in exists\n","    os.stat(path)\n","KeyboardInterrupt\n"]},{"output_type":"error","ename":"TypeError","evalue":"object of type 'NoneType' has no len()","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n","\u001b[0;32m<ipython-input-29-4a6438a9a9f0>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#model.train_fine_tuning(x_train, y_train, x_test, y_test, 50, 512, 150)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_fine_tuning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m150\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-20-22a9cb61a0d8>\u001b[0m in \u001b[0;36mtrain_fine_tuning\u001b[0;34m(self, X_train, y_train, X_test, y_test, epochs, batch_size, fine_tune_from)\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;31m# Riaddestra il modello\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             history = self.neural_network.fit(\n\u001b[0m\u001b[1;32m    182\u001b[0m                 \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    317\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pythonify_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1552\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1553\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: ","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2098\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2099\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2099\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2101\u001b[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[1;32m   2102\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[1;32m   2103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"]}],"source":["#model.train_fine_tuning(x_train, y_train, x_test, y_test, 50, 512, 150)\n","model.train_fine_tuning(x_train, y_train, x_test, y_test, 50, 128, 150)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eh8CgV3b44-6"},"outputs":[],"source":["model.neural_network.save('weights_xl_2.keras')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-KpPjlAs44-7"},"outputs":[],"source":["\"\"\"model2 = model.neural_network\n","model2.compile(\n","  loss=tfk.losses.CategoricalCrossentropy(),\n","  optimizer=tfk.optimizers.Lion(learning_rate=1e-4),\n","  metrics=['accuracy']\n",")\n","\n","model2.save('weights_squeeze.keras')\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BPTK4moBCGrc"},"outputs":[],"source":["# Carica il dataset\n","\"\"\"data_original = np.load('training_set.npz')\n","x_test = data_original['images']\n","y_test = data_original['labels']\"\"\"\n","\n","x_test = tf.cast(x_train, dtype=tf.float32)  # Convert to float32 if required\n","#y_test = tf.keras.utils.to_categorical(y_train, num_classes=8)\n","\n","print(f\"{y_train[0]} end\")\n","print(f\"{y_test[0]}\")\n","\n","\"\"\"# Load the model\n","model = tf.keras.models.load_model('weights_xl_2.keras')\n","\n","# Test the model on some data\n","# Get predictions\n","predictions = model.predict(x_train)\n","\n","# Evaluate the model\n","loss, accuracy = model.evaluate(x_train, y_train)\n","print(f\"Loss: {loss}, Accuracy: {accuracy}\")\n","\n","# Example: print the predicted class for the first sample\n","predicted_class = tf.argmax(predictions[0]).numpy()\n","print(f\"Predicted class for the first sample: {predicted_class}\")\"\"\"\n","\n","\n","model.test(x_test, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Syb4AHsnicdk"},"outputs":[],"source":["preds = model.predict(x_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_ystjv8Wun5B"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n","y_true = np.argmax(y_train, axis=1)\n","y_pred = preds\n","# Genera la confusion matrix\n","cm = confusion_matrix(y_true, y_pred)\n","# Visualizza la confusion matrix con le etichette\n","disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n","disp.plot(cmap=plt.cm.Blues)\n","# Usa una mappa di colori blu\n","plt.title(\"Confusion Matrix\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4qMqkETBBvj0"},"outputs":[],"source":["#model.neural_network.save('/gdrive/MyDrive/weights.keras')"]},{"cell_type":"markdown","metadata":{"id":"RNp6pUZuddqC"},"source":["## 📊 Prepare Your SubmissionTo prepare your submission, create a `.zip` file that includes all the necessary code to run your model. It **must** include a `model.py` file with the following class:```python# file: model.pyclass Model:    def __init__(self):        \"\"\"Initialize the internal state of the model.\"\"\"    def predict(self, X):        \"\"\"Return a numpy array with the labels corresponding to the input X.\"\"\"```The next cell shows an example implementation of the `model.py` file, which includes loading model weights from the `weights.keras` file and conducting predictions on provided input data. The `.zip` file is created and downloaded in the last notebook cell.❗ Feel free to modify the method implementations to better fit your specific requirements, but please ensure that the class name and method interfaces remain unchanged."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RKT4h-9xYwiT"},"outputs":[],"source":["%%writefile '/gdrive/My Drive/[2024-2025] AN2DL/Homework 1/Base_3/model.py'\n","\n","import numpy as np\n","\n","import tensorflow as tf\n","from tensorflow import keras as tfk\n","from tensorflow.keras import layers as tfkl\n","\n","class Model:\n","  def __init__(self):        # Carica il modello senza compilazione\n","    self.neural_network = tfk.models.load_model('weights.keras')\n","\n","  def test(self, X_test, y_test):\n","    test_loss, test_acc = self.neural_network.evaluate(X_test, y_test)\n","    print(f'Test accuracy: {test_acc}')\n","\n","  def predict(self, X):\n","    preds = self.neural_network.predict(X)\n","    if len(preds.shape) == 2:\n","      preds = np.argmax(preds, axis=1)\n","      return preds"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T9qoFhPzfa6D"},"outputs":[],"source":["#model3 = Model2()\n","#model3.test(X_test2, y_test2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BHm_n-9kSFpv"},"outputs":[],"source":["from datetime import datetime\n","\n","#filename1 = f'submission_{datetime.now().strftime(\"%y%m%d_%H%M%S\")}_NOFN.zip'\n","filename2 = f'submission_{datetime.now().strftime(\"%y%m%d_%H%M%S\")}_FN.zip'\n","\n","# Add files to the zip command if needed\n","#!zip {filename1} model.py weights_xl_1.keras\n","!zip {filename2} model.py weights_xl_2.keras\n","\n","from google.colab import files\n","#files.download(filename1)\n","files.download(filename2)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":6092801,"sourceId":9915012,"sourceType":"datasetVersion"},{"datasetId":6104425,"sourceId":9930890,"sourceType":"datasetVersion"},{"datasetId":6115708,"sourceId":9945705,"sourceType":"datasetVersion"}],"dockerImageVersionId":30787,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":0}